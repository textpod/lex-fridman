---
description: https://www.youtube.com/watch?v=_L3gNaAVjQ4
---

# George Hotz: Hacking the Simulation & Learning to Drive with Neural Nets | Lex Fridman Podcast #132

Date: 10/21/2020

Duration: 3 hours, 8 minutes, 46 seconds

Model: Whisper-small

The following is a conversation with George Hots, a.k.a. Geohot, his second time in the podcast. He's the founder of Kama AI, an autonomous and semi autonomous vehicle technology company that seeks to be, to Tesla autopilot, what Android is, to the iOS. They sell the Kama 2 device for $1,000 that when installed in many of their supported cars can keep the vehicle centered in the lane even when there are no lane markings. It includes driver sensing that ensures that the driver's eyes are on the road. As you may know, I'm a big fan of driver sensing.

I do believe Tesla autopilot and others should definitely include it in their sensor suite. Also, I'm a fan of Android and a big fan of George, for many reasons, including his nonlinear out of the box brilliance and the fact that he's a superstar programmer of a very different style than myself. Styles make fights and styles make conversations. So I really enjoyed this chat. I'm sure we'll talk many more times on this podcast. Quick mention of a sponsor followed by some thoughts related to the episode. First is ForSigmatic, the maker of delicious mushroom coffee. Second is the coding digital, a podcast on tech and entrepreneurship that I listen to and enjoy.

And finally, ExpressVPN, the VPN I've used for many years to protect my privacy on the internet. Please check out the sponsors in the description to get a discount and to support this podcast. As a side note, let me say that my work at MIT on autonomous and semi autonomous vehicles led me to study the human side of autonomy enough to understand that it's a beautifully complicated and interesting problem space much richer than what can be studied in the lab. In that sense, the data that comma AI, Tesla autopilot and perhaps others like Cadillac supercruiser collecting gives us a chance to understand how we can design safe semi autonomous vehicles for real human beings in real world conditions.

I think this requires bold innovation and a serious exploration of the first principles of the driving task itself. If you enjoyed this thing, subscribe on YouTube, review it with five stars and up a podcast, follow on Spotify, support on Patreon or connect with me on Twitter at Lex Friedman. And now here's my conversation with George Hottz. So last time we started talking about the simulation, this time let me ask you, do you think there's intelligent life out there in the universe? I always maintained my answer to the Fermi paradox. I think there has been intelligent life elsewhere in the universe.

So intelligent civilizations existed, but they've blown themselves up. So your general intuition is that intelligent civilizations quickly, like there's that parameter in the Drake equation, your sense is they don't last very long. How are we doing on that? Have we lasted pretty good? How do we do? Yeah. I mean, not quite yet. I tell you, as Yuckowski, IQ required to destroy the world falls by one point every year. Okay. So technology democratizes the destruction of the world. When can a meme destroy the world? It kind of is already, right? Somewhat. I don't think we've seen anywhere near the worst of it yet.

World's going to get weird. Well, maybe a meme can save the world. You thought about that, the meme Lord Elon Musk fighting on the side of good versus the meme Lord of the darkness, which is not saying anything bad about Donald Trump, but he is the Lord of the meme on the dark side. He's a Darth Vader of memes. I think in every fairy tale, they always end it with, and they lived happily ever after. And I'm like, please tell me more about this happily ever after. I've heard 50% of marriages end in divorce. Why doesn't your marriage end up there? You can't just say happily ever after.

So the thing about destruction is it's over after the destruction. We have to do everything right in order to avoid it. And one thing wrong. Actually, this is what I really like about cryptography. Cryptography, it seems like we live in a world where the defense wins versus nuclear weapons. The opposite is true. It is much easier to build a warhead that splits into 100 little warheads than to build something that can take out 100 little warheads. The offense has the advantage there. So maybe our future is in crypto. So cryptography, right. The Goliath is the defense.

And then all the different hackers are the Davids. And that equation is flipped for nuclear war. Because there's so many, like one nuclear weapon destroys everything, essentially. Yeah. And it is much easier to attack with a nuclear weapon than it is to like, the technology required to intercept and destroy a rocket is much more complicated than the technology required to just orbital trajectory, send a rocket to somebody. So okay, your intuition that there were intelligent civilizations out there, but it's very possible that they're no longer there. It's kind of a sad picture. They enter some steady state.

They all wirehead themselves. What's wirehead? Stimulate their pleasure centers and just live forever in this kind of stasis. Oh. Well, I mean, I think the reason I believe this is because where are they? If there's some reason they stopped expanding, because otherwise they would have taken over the universe. The universe isn't that big. Or at least, you know, let's just talk about the galaxy, right? About 70,000 light years across. I took that number from Star Trek Voyager. I don't know how true it is. But yeah, that's not big, right? 70,000 light years is nothing. For some possible technology that you can imagine that can leverage like wormholes or something like that.

You don't even need wormholes. Just a von Neumann probe is enough. A von Neumann probe and a million years of sub light travel, and you'd have taken over the whole universe. That clearly didn't happen. So something stopped it. So you mean for like a few million years, if you sent out probes that travel close, what's sub light? You mean close to the speed of light? Let's say 0.1c. And it just spreads. Interesting. Actually, that's an interesting calculation. So what makes you think that we'd be able to communicate with them? Why do you think we would be able to comprehend intelligent lies that are out there? Even if they were among this kind of thing, or even just flying around? Well, I mean, that's possible.

It's possible that there is some sort of prime directive. That'd be a really cool universe to live in. And there's some reason they're not making themselves visible to us. But it makes sense that they would use the same, well, at least the same entropy. Well, you're implying the same laws of physics. I don't know what you mean by entropy in this case. Oh, yeah. I mean, if entropy is the scarce resource in the universe. So what do you think about like Steven Wolfram and everything is a computation? And then what if they are traveling through this world of computation? So if you think of the universe as just information processing, then what you're referring to with entropy, and then these pockets of interesting complex computation swimming around, how do we know they're not already here? How do we know that all the different amazing things that are full of mystery on Earth are just like little footprints of intelligence from light years away? Maybe.

I mean, I tend to think that as civilizations expand, they use more and more energy. And you can never overcome the problem of waste heat. So where is their waste heat? So we'd be able to, with our crude methods, be able to see like there's a whole lot of energy here. But it could be something we're not, I mean, we don't understand dark energy, right? Dark matter. It could be just stuff we don't understand at all. Or they could have a fundamentally different physics, you know, like that we just don't even comprehend. Well, I think, okay, I mean, it depends how far out you want to go.

I don't think physics is very different on the other side of the galaxy. I would suspect that they have, I mean, if they're in our universe, they have the same physics. Well, yeah, that's the assumption we have. But there could be like super trippy things like like our cognition only gets to a slice and all the possible instruments that we can design only get to a particular slice of the universe. And there's something much like weirder. Maybe we can try a thought experiment. Would people from the past be able to detect their remnants of our, be able to detect our modern civilization? I think the answer is obviously yes.

You mean past from a hundred years ago? Well, let's even go back further. Let's go to a million years ago. The humans who were lying around in the desert probably didn't even have, maybe they just barely had fire. They would understand if a 747 flew overhead. Oh, in this vicinity, but not if a 747 flew on Mars. Because they wouldn't be able to see far, because we're not actually communicating that well with the rest of the universe. We're doing okay, just sending out random like 50s tracks of music. True. And yeah, I mean, they'd have to do, you know, the, we've only been broadcasting radio waves for 150 years and well, there's your light cone.

So yeah, okay. What do you make about all the, I recently came across this, having talked to David Fravor. I don't know if you caught what the videos that Pentagon released and the New York Times reporting of the UFO sightings. So I kind of looked into it quote unquote. And there's actually been like hundreds of thousands of UFO sightings, right? And a lot of it you can explain away in different kinds of ways. So one is it could be interesting physical phenomena. Two, it could be people wanting to believe. And therefore they conjure up a lot of different things that just, you know, when you see different kinds of lights, some basic physics phenomena, and then you just conjure up ideas of possible out there mysterious worlds.

But, you know, it's also possible like you have a case of David Fravor, who is a Navy pilot, who's, you know, as legit as it gets in terms of humans who are able to perceive things in the environment and make conclusions, whether those things are a threat or not. And he and several other pilots saw a thing, I don't know if you followed this, but they saw a thing that they've since then called TikTok that moved in all kinds of weird ways. They don't know what it is. It could be technology developed by the United States, and they're just not aware of it and the surface level from the Navy, right? It could be different kind of lighting technology or drone technology, all that kind of stuff.

It could be the Russians and the Chinese, all that kind of stuff. And of course their mind, our mind can also venture into the possibility that it's from another world. Have you looked into this at all? What do you think about it? I think all the news is a scythe. I think that the most plausible... Nothing is real. Yeah, I listened to the, I think it was Bob Lazar on Joe Rogan. And like, I believe everything this guy is saying. And then I think that it's probably just some like MK Ultra kind of thing, you know? What do you mean? Like, they made some weird thing and they called it an alien spaceship.

You know, maybe it was just to like stimulate young physicists minds and tell them it's alien technology and we'll see what they come up with, right? Do you find any conspiracy theories compelling? Like, have you pulled at the string of the rich complex world of conspiracy theories that's out there? I think that I've heard a conspiracy theory that conspiracy theories were invented by the CIA in the 60s to discredit true things. Yeah. So, you know, you can go to ridiculous conspiracy theories like Flat Earth and Pizza Gate and, you know, these things are almost to hide like conspiracy theories that like, you know, remember when the Chinese like locked up the doctors who discovered coronavirus? Like, I tell people this and I'm like, no, no, no, that's not a conspiracy theory.

That actually happened. Do you remember the time that the money used to be backed by gold and now it's backed by nothing? This is not a conspiracy theory. This actually happened. Well, that's one of my worries today with the idea of fake news is that when nothing is real, then like, you dilute the possibility of anything being true by conjuring up all kinds of conspiracy theories. And then you don't know what to believe. And then like, the idea of truth of objectivity is lost completely. Everybody has their own truth. So, you used to control information by censoring it.

Then the internet happened and governments were like, oh, shit, we can't censor things anymore. I know what we'll do. You know, it's the old story of the story of like tying a flag with a leprechaun tells you as gold is buried and you tie one flag and you make the leprechaun swear to not remove the flag and you come back to the field later with a shovel and this flag is everywhere. That's one way to maintain privacy, right? In order to protect the contents of this conversation, for example, we could just generate like millions of deep fake conversations where you and I talk and say random things.

So, this is just one of them and nobody knows which one is the real one. This could be fake right now. Classic steganography technique. Okay, another absurd question about intelligent life because you're an incredible programmer outside of everything else we'll talk about just as a programmer. Do you think intelligent beings out there, the civilizations that were out there had computers and programming? Did they naturally have to develop something where we engineer machines and are able to encode both knowledge into those machines and instructions that process that knowledge, process that information to make decisions and actions and so on? And would those programming languages, if you think they exist, be at all similar to anything we've developed? So, I don't see that much of a difference between quote unquote natural languages and programming languages.

I think there are so many similarities. So, when asked the question what do alien languages look like, I imagine they're not all that dissimilar from ours, and I think translating in and out of them wouldn't be that crazy. Well, it's difficult to compile DNA to Python and then to C. There is a little bit of a gap in the kind of languages we use for touring machines and the kind of languages nature seems to use a little bit. Maybe that's just we just haven't understood the kind of language that nature uses as well yet. DNA is a CAD model.

It's not quite a programming language. It has no sort of serial execution. It's not quite a CAD model. So, I think in that sense we actually completely understand it. The problem is simulating on these CAD models. I played with it a bit this year is super computationally intensive. If you want to go down to like the molecular level where you need to go to see a lot of these phenomenon like protein folding. So, yeah, it's not that we don't understand it. It just requires a whole lot of compute to kind of compile it. For human minds it's inefficient both for the data representation and for the programming.

It runs well on raw nature. It runs well on raw nature and when we try to build emulators or simulators for that, well the mad sloth kind of tried it. It runs in that, yeah, you've commented elsewhere. I don't remember where that one of the problems is simulating nature is tough. And if you want to sort of deploy a prototype, I forgot how you put it but it made me laugh, but animals or humans would need to be involved in order to you know, to try to run some prototype code on like if we're talking about COVID and viruses and so on.

Yeah. If you were to try to engineer some kind of defense mechanisms like a vaccine against COVID or all that kind of stuff that doing any kind of experimentation like you can with like autonomous vehicles would be very technically cost, technically and ethically costly. I'm not sure about that. I think you can do tons of crazy biology in test tubes. I think my bigger complaint is more all the tools are so bad. Like literally you mean like like libraries and I don't know. I'm not pipetting shit. Like your hand in me, I gotta, no, no, no, there has to be some like automating stuff and like the human biology is messy.

Like it seems like look at those Taranos videos. They were joke. It's like a little gantry. It's like a little xy gantry high school science project with the pipet. I'm like, really? Gotta be something better. You can't build like nice microfluidics and I can program the, you know, computation to bio interface. I mean, this is going to happen. But like right now, if you are asking me to pipet 50 milliliters of solution, I'm out. This is so crude. Yeah. Okay, let's get all the crazy out of the way. So a bunch of people asked me, since we talked about the simulation last time, we talked about hacking the simulation.

Do you have any updates, any insights about how we might be able to go about hacking simulation if we indeed do live in a simulation? I think a lot of people misinterpreted the point of that South by talk. The point of the South by talk was not literally to hack the simulation. I think that this this is an idea is literally just I think theoretical physics. I think that's the whole, you know, the whole goal, right? You want your grand unified theory, but then, okay, build a grand unified theory search for exploits, right? I think we're nowhere near actually there yet.

My hope with that was just more to like, like, are you people kidding me with the things you spend time thinking about? Do you understand like kind of how small you are? You are, you are bytes and God's computer. Really? And the things that people get worked up about and, you know. So basically, it was more a message of we should humble ourselves that we get to like, what are we humans in this byte code? Yeah. And not just humble ourselves, but like, I'm not trying to like make people guilty or anything like that. I'm trying to say like, literally, look at what you are spending time on, right? What are you referring to? You're referring to the Kardashians? What are we talking about? I'm referring to no, the Kardashians.

Everyone knows that's kind of fun. I'm referring more to like, economy, you know, this idea that we got up our stock price. Or what is the goal function of humanity? You don't like the game of capitalism? Like, you don't like the games we've constructed for ourselves as humans? I'm a big fan of capitalism. I don't think that's really the game we're playing right now. I think we're playing a different game where the rules are rigged. Okay, which games are interesting to you that we humans have constructed and which aren't? Which are productive and which are not? Actually, maybe that's the real point of the talk.

It's like, stop playing these fake human games. There's a real game here. We can play the real game. The real game is, you know, nature wrote the rules. This is a real game. There still is a game to play. But if you look at, sorry to interrupt, I don't know if you've seen the Instagram account, nature is metal. The game that nature seems to be playing is a lot more cruel than we humans want to put up with. Or at least we see it as cruel. It's like, the bigger thing eats the smaller thing and does it to impress another big thing so it can mate with that thing.

And that's it. That seems to be the entirety of it. Well, there's no art. There's no music. There's no comma AI. There's no comma one, no comma two, no George Hott's with his brilliant talks at South by Southwest. See, I disagree though. I disagree that this is what nature is. I think nature just provided basically an open world MMORPG. And you know, here it's open world. I mean, if that's the game you want to play, you can play that game. Isn't that beautiful? I know if you play Diablo, they used to have, I think, cow level where it's, so everybody will go just, they figured out this, like the best way to gain experience points.

This is just slaughter cows over and over and over. And so they figured out this little sub game within the bigger game that this is the most efficient way to get experience points. And everybody somehow agreed they're getting experience points in RPG context where you always want to be getting more stuff, more skills, more levels, keep advancing. That seems to be good. So might as well spend sacrifice, actual enjoyment of playing a game, exploring a world, and spending like hundreds of hours a year time in cow level. I mean, the number of hours I spent in cow level, I'm not like the most impressive person because people have probably thousands of hours there, but it's ridiculous.

So that's a little absurd game that brought me joints on weird dopamine drug kind of way. So you don't like those games. You don't think that's us humans feeling the nature. And that was the point of the talk. So how do we hack it then? Well, I want to live forever. And this is the goal. Well, that's a game against nature. Yeah. Immortality is the good objective function to you. I mean, start there and then you can do whatever else you want because you've got a long time. What if immortality makes the game just totally not fun? I mean, why do you assume immortality is somehow a good objective function? It's not immortality that I want.

A true immortality where I could not die, I would prefer what we have right now. But I want to choose my own death, of course. I don't want nature to decide when I die, I'm going to win. I'm going to be you. And then at some point, if you choose commit suicide, how long do you think you'd live? Until I get bored. See, I don't think people, like brilliant people like you that really ponder they're living a long time, are really considering how meaningless life becomes. Well, I want to know everything and then I'm ready to die.

As long as there's... But why do you want, isn't it possible that you want to know everything because it's finite? Like the reason you want to know quote unquote, everything is because you don't have enough time to know everything. And once you have unlimited time, then you realize like, why do anything? Like why learn anything? I want to know everything and then I'm ready to die. So you have... Yeah. Well, it's not a... It's a terminal value. It's not in service of anything else. I'm conscious of the possibility, this is not a certainty, but the possibility of that engine of curiosity that you're speaking to is actually a symptom of the finiteness of life.

Like without that finiteness, your curiosity would vanish like a morning fog. All right, cool. Bukowski talked about love like that. Then let me solve immortality. Let me change the thing in my brain that reminds me of the fact that I'm immortal tells me that life is finite shit. Maybe I'll have it tell me that life ends next week. All right? I'm okay with some self manipulation like that. I'm okay with deceiving myself. Oh, oh, Rika. Changing the code. If that's the problem, right? If the problem is that I will no longer have that curiosity, I'd like to have backup copies of myself.

Revert, yeah. Well, which I check in with occasionally to make sure they're okay with the trajectory and they can kind of override it. Maybe a nice like, I think of like those wave nets, those like logarithmic go back to the copies. But sometimes it's not reversible. Like I've done this with video games. Once you figure out the cheat code or like you look up how to cheat old school, like single player, it ruins the game for you. Absolutely. I know that feeling. But again, that just means our brain manipulation technology is not good enough yet.

Remove that cheat code from your brain. So it's also possible that if we figure out immortality that all of us will kill ourselves before we advance far enough to be able to revert the change. I'm not killing myself till I know everything. So... That's what you say now because your life is finite. You know, I think self modifying systems comes up with all these hairy complexities. And can I promise that I'll do it perfectly? No. But I think I can put good safety structures in place. So that talk and your thinking here is not literally referring to a simulation in that our universe is a kind of computer program running on a computer.

That's more of a thought experiment. Do you also think of the potential of the sort of Bostrom, Elon Musk, and others that talk about an actual program that simulates our universe? Oh, I don't doubt that we're in a simulation. I just think that it's not quite that important. I mean, I'm interested only in simulation theory as far as like it gives me power over nature. If it's totally unfalsifiable, then who cares? I mean, what do you think that experiment would look like? Like somebody on Twitter asked George what signs we would look for to know whether or not we're in the simulation, which is exactly what you're asking is like the step that precedes the step of knowing how to get more power from this knowledge is to get an indication that there's some power to be gained.

So get an indication that you can discover and exploit cracks in the simulation or it doesn't have to be in the physics of the universe. Yeah. Show me. I mean, like a memory leak would be cool. Some scrying technology, you know? What kind of technology? Scrying. What's that? Oh, that's a weird. Scrying is the paranormal ability to like remote viewing, like being able to see somewhere where you're not. So, you know, I don't think you can do it by chanting in a room, but if we could find, it's a memory leak, basically. It's a memory leak.

Yeah. You're able to access parts you're not supposed to. Yeah, yeah, yeah. And thereby discover shortcut. Yeah. Maybe a memory leak means the other thing as well, but I mean like, yeah, like an ability to read arbitrary memory. Yeah. Right. And that one's not that horrifying. All right. The right ones start to be horrifying. Read it. Right. So the reading is not the problem. Yeah. It's like Heartbleed for the universe. Oh, boy, the writing is a big, big problem. It's a big problem. It's the moment you can write anything, even if it's just random noise.

That's terrifying. I mean, even without, even without that, like even some of the, you know, the nanotech stuff that's coming, I think. I don't know if you're paying attention, but actually, Eric Weisstein came out with the theory of everything. I mean, that came out. He's been working on a theory of everything in the physics world called geometric unity. And then for me, from computer science person, like you, Steven Wolfram's theory of everything, of like, hypergraphs is super interesting and beautiful. But not from a physics perspective, but from a computational perspective. I don't know. Have you paid attention to any of that? So again, like what would make me pay attention and like why like a hate string theory is, okay, make a testable prediction.

Right. I'm only interested in, I'm not interested in theories for their intrinsic beauty. I'm interested in theories that give me power over the universe. So if these theories do, I'm very interested. Can I just say how beautiful that is? Because a lot of physicists say, I'm interested in experimental validation, and they skip out the part where they say, to give me more power in the universe. I just love the, yo, I want, I want, I want the clarity of that. I want a hundred gigahertz processors. I want transistors that are smaller than atoms. I want like power.

That's, that's true. And that's where people from aliens to this kind of technology where people are worried that governments, like who owns that power? Is it George Haas? Is it thousands of distributed hackers across the world? Is it governments? You know, is it Mark Zuckerberg? There's a lot of people that, I don't know if anyone trusts anyone individual with power, so they're always worried. It's the beauty of blockchains. That's the beauty of blockchains, which we'll talk about. On Twitter, somebody pointed me to a story, a bunch of people pointed me to a story a few months ago where you went into a restaurant in New York, and you can correct me if any of this is wrong, and ran into a bunch of folks from a company, a crypto company, who are trying to scale up Ethereum, and they had a technical deadline related to a solidity to OVM compiler.

So these are all Ethereum technologies. So you stepped in, they recognized you, pulled you aside, explained their problem, and you stepped in and helped them solve the problem, thereby creating legend status story. Can you tell me the story a little more detail? It seems kind of incredible. Did this happen? Yeah, yeah, it's a true story. It's a true story. I mean, they wrote a very flattering account of it. So optimism is the spin, the company's called Optimism. It's a spin off of Plasma. They're trying to build L2 solutions on Ethereum. So right now, every Ethereum node has to run every transaction on the Ethereum network.

And this kind of doesn't scale, right? Because if you have n computers, well, if that becomes two n computers, you actually still get the same amount of compute. This is like O of 1 scaling, because they all have to run it. Okay, fine, you get more blockchain security, but the blockchain's already so secure. Can we trade some of that off for speed? That's kind of what these L2 solutions are. They built this thing, which kind of sandbox for Ethereum contracts, so they can run it in this L2 world, and it can't do certain things in L1.

Can I ask you for some definitions? What's L2? Oh, L2 is Layer 2. So L1 is like the base Ethereum chain, and then Layer 2 is like a computational layer that runs elsewhere, but still is kind of secured by Layer 1. And I'm sure a lot of people know, but Ethereum is a cryptocurrency, probably one of the most popular cryptocurrency, second to Bitcoin. And a lot of interesting technological innovations there. Maybe you could also slip in whenever you talk about this, any things that are exciting to you in the Ethereum space. And why Ethereum? Well, I mean, Bitcoin is not turned complete.

Ethereum is not technically turned complete with a gas limit, but close enough. With a gas limit? What's the gas limit? Resources? Yeah, I mean, no computer is actually turned complete. They're just fine at RAM. You know, guys, I can actually solve the whole problem. What's the word gas limit? You just have so many brilliant words. I'm not even going to ask. Well, that's not my word. That's Ethereum's word. Gas limit. Ethereum, you have to spend gas per instruction. So like different op codes, you use different amounts of gas, and you buy gas with Ether to prevent people from basically DDoSing the network.

So Bitcoin is proof of work. And then what's Ethereum? It's also proof of work. They're working on some proof of stake Ethereum 2.0 stuff. But right now it's proof of work. It uses a different hash function from Bitcoin. That's more ASIC resistance because you need RAM. So we're all talking about Ethereum 1.0. So what were they trying to do to scale this whole process? So they were like, well, if we could run contracts elsewhere, and then only save the results of that computation, well, we don't actually have to do the compute on the chain. We can do the compute off chain and just post what the results are.

Now, the problem with that is, well, somebody could lie about what the results are. So you need a resolution mechanism. And the resolution mechanism can be really expensive because you just have to make sure that the person who is saying, look, I swear that this is the real computation. I'm staking $10,000 on that fact. And if you prove it wrong, yeah, it might cost you $3,000 in gas fees to prove wrong, but you'll get the $10,000 bounty. So you can secure using those kind of systems. So it's effectively a sandbox which runs contracts. And like just like any kind of normal sandbox, you have to replace syscalls with calls into the hypervisor.

Uh, sandbox, syscalls, hypervisor, what do these things mean? As long as it's interesting to talk about. Yeah, I mean, you can take like the Chrome sandbox is maybe the one to think about, right? So the Chrome process is doing a rendering. Can't, for example, read a file from the file system. Yeah. It has, if it tries to make an open syscall in Linux, the open syscall, you can't make an open syscall. No, no, no. You have to request from the kind of a hypervisor process or like, I don't know what it's called in Chrome. But the, hey, could you open this file for me? And then it does all these checks and then it passes the file, handle back in if it's approved.

Got it. So that's, yeah. So what's the, in the context of Ethereum, what are the boundaries of the sandbox that we're talking about? Well, like one of the calls that you actually reading and writing any state to the Ethereum contract, to the Ethereum blockchain. Writing state is one of those calls that you're going to have to sandbox in layer two, because if you let layer two just arbitrarily write to the Ethereum blockchain. So layer two is really sitting on top of layer one. So you're going to have a lot of different kinds of ideas that you can play with.

Yeah. And they're all, they're not fundamentally changing the source code level of Ethereum. Well, you have to replace a bunch of calls with calls into the hypervisor. So instead of doing the syscall directly, you, you replace it with a call to the hypervisor. So originally they were doing this by first running the, so solidity is the language that most Ethereum contracts are written in, it compiles to a bytecode. And then they wrote this thing they called the transpiler. And the transpiler took the bytecode and it transpiled it into OVM safe bytecode, basically bytecode that didn't make any of those restricted syscalls and added the calls to the hypervisor.

This transpiler was a 3000 line mess. And it's hard to do. It's hard to do if you're trying to do it like that, because you have to kind of like deconstruct the bytecode, change things about it, and then reconstruct it. And I mean, as soon as I hear this, I'm like, well, why don't you just change the compiler? All right. Why not the first place you build the bytecode, just do it in the compiler? So, yeah, you know, I asked them how much they wanted it. Of course, measured in dollars and I'm like, well, okay.

And yeah. You wrote the compiler. Yeah, I modified. I wrote a 300 line diff to the compiler. It's on source. You can look at it. Yeah, I looked at the code last night. Yeah, it's cute. Yeah, exactly. Oh, too massive. Cute is a good word for it. And it's C++. C++, yeah. So, when asked how you were able to do it, you said you just got to think and then do it right. So, can you break that apart a little bit? What's your process of one, thinking, and two, doing it right? You know, the people who I was working for were amused that I said that.

It doesn't really mean anything. Okay. Yeah, I mean, is there some deep profound insights to draw from like how you problem solve from that? This is always what I say. I'm like, do you want to be a good programmer? Do it for 20 years? Yeah, there's no shortcuts. Yeah. What are your thoughts on crypto in general? So, what parts technically or philosophically define especially beautiful maybe? Oh, I'm extremely bullish on crypto long term. Not any specific crypto project, but this idea of, well, two ideas. One, the Nakamoto consensus algorithm is I think one of the greatest innovations of the 21st century.

This idea that people can reach consensus. You can reach a group consensus using a relatively straightforward algorithm is wild. And like Satoshi Nakamoto, people always ask me who I look up to. It's like whoever that is. Who do you think it is? Elon Musk? Is it you? It is definitely not me and I do not think it's Elon Musk. But yeah, this idea of groups reaching consensus in a decentralized yet formulaic way is one extremely powerful idea from crypto. Maybe the second idea is this idea of smart contracts. When you write a contract between two parties, any contract, this contract, if there are disputes, it's interpreted by lawyers.

Lawyers are just really shitty overpaid interpreters. Imagine you had, let's talk about them in terms of like, let's compare a lawyer to Python. Right? Well, okay. That's brilliant. Oh, I never thought of it that way. It's hilarious. So Python, I'm paying even 10 cents an hour. I'll use the nice Azure machine. I can run Python for 10 cents an hour. Lawyers cost $1,000 an hour. So Python is 10,000x better on that axis. Lawyers don't always return the same answer. Python almost always does. Cost. Yeah. I mean, just cost, reliability, everything about Python is so much better than lawyers.

So if you can make smart contracts, this whole concept of code is law. I love and I would love to live in a world where everybody accepted that fact. So maybe you can talk about what smart contracts are. So let's say we have even something as simple as a safety deposit box. A safety deposit box that holds a million dollars. I have a contract with the bank that says two out of these three parties must be present to open the safety deposit box and get the money out. So that's a contract with the bank and it's only as good as the bank and the lawyers.

Let's say somebody dies and now we're going to go through a big legal dispute about whether, oh, was it in the will? Was it not in the will? It's just so messy and the cost to determine truth is so expensive. Versus a smart contract, which just uses cryptography to check if two out of three keys are present. Well, I can look at that and I can have certainty in the answer that it's going to return. And that's what all businesses want is certainty. You know, they say businesses don't care via YouTube. YouTube's like, look, we don't care which way this lawsuit goes.

Just please tell us so we can have certainty. And I wonder how many agreements in this, because we're talking about financial transactions only in this case, correct? The smart contracts. Oh, you can go to anything. You can put a prenup in the theorem blockchain. Married smart contract. Sorry, divorce lawyer. Sorry, you're going to be replaced by Python. Okay, so that's another beautiful idea. Do you think there's something that's appealing to you about any one specific implementation? So if you look 10, 20, 50 years down the line, do you see any like Bitcoin, Ethereum, any of the other hundreds of cryptocurrencies winning out? Is there like, what's your intuition about the space? Are you just sitting back and watching the chaos and look who cares what emerges? Oh, I don't.

I don't speculate. I don't really care. I don't really care which one of these projects wins. I'm kind of in the Bitcoin as a meme coin camp. I mean, why does Bitcoin have value? It's technically kind of not great, like the block size debate. When I found out what the block size debate was, I'm like, are you guys kidding? What's the block size debate? You know what? It's really, it's too stupid to even talk. People can look it up, but I'm like, wow. Ethereum seems, the governance of Ethereum seems much better. I've come around a bit on proof of stake ideas.

Because very smart people thinking about some things. Yeah, governance is interesting. It does feel like Vitalik, it does feel like it opens, even in these distributed systems, leaders are helpful because they kind of help you drive the mission and the vision and they put a face to a project. It's a weird thing about us humans. Geniuses are helpful, like Vitalik. Right. Yeah, brilliant. Leaders, I mean. Are not necessarily, yeah. So you think the reason he's the face of Ethereum is because he's a genius. That's interesting. It's interesting to think about that we need to create systems in which the quote unquote leaders that emerge are the geniuses in the system.

I mean, that's arguably why the current state of democracy is broken is the people who are emerging as the leaders are not the most competent, are not the superstars of the system. And it seems like at least for now in the crypto world, oftentimes the leaders are the superstars. Imagine at the debate, they asked, what's the Sixth Amendment? What are the four fundamental forces in the universe? Right. What's the integral of two to the X? Yeah, I'd love to see those questions asked. And that's what I want as our leader. What's Bayes rule? Yeah, I mean, even, oh, wow, you're hurting my brain.

My standard was even lower, but I would have loved to see just this basic brilliance. Like I've talked to historians. There's just these, they're not even like, they don't have a PhD or even education history. They just like a Dan Carlin type character who just like, holy shit, how did all this information get into your head? They're able to just connect Genghis Khan to the entirety of the history of the 20th century. They know everything about every single battle that happened. And they know the game of thrones of the different power plays and all that happened there.

And they know the individuals and all the documents involved. And they integrate that into their regular life. It's not like they're ultra history nerds. They're just, they know this information. That's what competence looks like. Yeah. Because I've seen that with programmers too, right? That's what great programmers do. But yeah, it would be, it's really unfortunate that those kinds of people aren't emerging as our leaders. But for now, at least in the crypto world, that seems to be the case. I don't know if that always, you could imagine that in 100 years, it's not the case, right? Crypto world has one very powerful idea going for it.

And that's the idea of forks, right? I mean, imagine, we'll use a less controversial example, this was actually in my joke app in 2012, I was like, Barack Obama, Mitt Romney, let's let them both be president, right? Like imagine we could fork America and just let them both be president. And then the Americas could compete and people could invest in one, pull their liquidity out of one, put it in the other. You have this in the crypto world. Ethereum forks into Ethereum and Ethereum Classic. And you can pull your liquidity out of one and put it in another.

And people vote with their dollars, which forks, companies should be able to fork. I'd love to fork Nvidia. Yeah, like different business strategies and then try them out and see what works. Like even take, yeah, take common AI that closes its source and then take one that's open source and see what works, take one that's purchased by GM and one that remains Android Renegade in all these different versions and see. The beauty of common AI is someone can actually do that. Please take common AI and fork it. That's right. That's the beauty of open source.

So you're, I mean, we'll talk about autonomous vehicle space, but it does seem that you're really knowledgeable about a lot of different topics. So the natural question a bunch of people ask this, which is, how do you keep learning new things? Do you have like practical advice? If you were to introspect, like taking notes, allocate time, or do you just mess around and just allow your curiosity to drive? I'll write these people a self help book and I'll charge $67 for it. And I will write on the cover of the self help book. All of this advice is completely meaningless.

You're going to be a sucker and buy this book anyway. And the one lesson that I hope they take away from the book is that I can't give you a meaningful answer to that. That's interesting. And let me translate that is you haven't really thought about what it is you do systematically because you could reduce it. And there's some people, I mean, I've met brilliant people that this is really clear with athletes. Some are just, you know, the best in the world at something. And they, they have zero interest in writing a, like a self help book, but or how to master this game.

And then there's some athletes who become great coaches and they love the analysis, perhaps the overall analysis. And you right now, at least at your age, which is an interesting, you're in the middle of the battle. You're like the warriors that have zero interest in writing books. So you're in the middle of the battle. So you have, yeah. This is, this is a fair point. I do think I have a certain aversion to this kind of deliberate, intentional way of living life. You eventually, the hilarity of this, especially since this is recorded, it will reveal beautifully the absurdity when you finally do publish this book.

That guarantee you will. The story of comma AI, maybe it'll be a biography written about you. That'll be, that'll be better, I guess. And you might be able to learn some cute lessons if you're starting a company like comma AI from that book. But if you're asking generic questions like, how do I be good at things? Dude, I don't know. Well, learn, I mean, the interesting, Do them a lot. Do them a lot. But the interesting thing here is learning things outside of your current trajectory, which is what it feels like from an outsider's perspective.

I don't know if there's a device on that, but it is an interesting curiosity. When you become really busy, you're running a company. Hard time. Yeah. But like, there's a natural inclination and trend, like just the momentum of life carries you into a particular direction of wanting to focus. And this kind of dispersion that curiosity can lead to gets harder and harder with time. Because you get really good at certain things and it sucks trying things that you're not good at, like trying to figure them out. When you do this with your live streams, you're on the fly figuring stuff out.

You don't mind looking dumb. You just figured out, figured out pretty quickly. Sometimes I try things and I don't figure them out. You fail. My chest rating is like a 1400 despite putting like a couple of hundred hours in. It's pathetic. I mean, to be fair, I know that I could do it better. If I did it better, like, don't play, you know, don't play five minute games, play 15 minute games at least. Like, I know these things, but it just doesn't. It doesn't stick nicely in my knowledge stream. All right. Let's talk about Kama AI.

What's the mission of the company? Let's like look at the biggest picture. Oh, I have an exact statement. Solve self driving cars while delivering shipable intermediaries. So long term vision is have fully autonomous vehicles and make sure you're making money along the way. I think it doesn't really speak to money, but I can talk. I can talk about what solve self driving cars means. Solve self driving cars, of course, means you're not building a new car. You're building a person replacement that person can sit in the driver's seat and drive you anywhere a person can drive with a human or better level of safety, speed, quality, comfort.

And what's the second part of that? Deliver and shipable intermediaries is, well, it's a way to fund the company. That's true. But it's also a way to keep us honest. If you don't have that, it is very easy with this technology to think you are making progress when you're not. I've heard it best described on Hacker News as you can set any arbitrary milestone, meet that milestone, and still be able to do that. Meet that milestone and still be infinitely far away from solving self driving cars. So it's hard to have like real deadlines when you're like cruise or Waymo when you don't have revenue.

Is that, I mean, is revenue essentially the thing we're talking about here? Revenue is, capitalism is based around consent. Capitalism, the way that you get revenue is a kind of real capitalism. Common is in the real capitalism camp. There's definitely scams out there, but real capitalism is based around consent. It's based around this idea that like, if we're getting revenue, it's because we're providing at least that much value to another person. When someone buys $1,000 comma two from us, we're providing them at least $1,000 of value, but they wouldn't buy it. Brilliant. So can you give a world wind overview of the products that Kamiai provides throughout its history and today? I mean, yeah, the past ones aren't really that interesting.

It's kind of just been refinement of the same idea. The real only product we sell today is the comma two. Which is a piece of hardware with cameras. So the comma two, I mean, you can think about it kind of like a person. You know, in future hardware will probably be even more and more person like. So it has, you know, eyes, ears, a mouth, a brain, and a way to interface with the car. Does it have consciousness? Just kidding. That was a trick question. I don't have consciousness either. Me and the comma two are the same.

You're the same? I have a little more compute than it. It only has like the same computer. How interesting. B, you know. You're more efficient energy wise for the compute you're doing. Far more efficient energy wise. 20 pay to flops, 20 wants, crazy. Do you lack consciousness? Sure. Do you fear death? You do. You want immortality? Of course I fear death. Does Kamiai fear death? I don't think so. I don't think so. Of course it does. It very much fears, well, fears negative loss. Oh, yeah. Okay. So comma two, when did that come out? That was a year ago? No, two.

Early this year. Wow. Time, it feels, yeah. To 2020 feels like it's taken 10 years to get to the end. It's a long year. It's a long year. So what's the sexiest thing about comma two, feature wise? So, I mean, maybe you can also link on like, what is it? Like, what's its purpose? Because there's a hardware, there's a software component. You've mentioned the sensors, but also like, what is it, its features and capabilities? I think our slogan summarizes it well. Comma slogan is make driving chill. I love it. Yeah, I mean, it is, you know, if you like cruise control, imagine cruise control, but much, much more.

So it can do adaptive cruise control things, which is like slow down for cars in front of it, maintain a certain speed. And it can also do lane keeping, so stay in the lane and do it better and better and better over time. That's very much machine learning based. So there's cameras, there's a driver facing camera too. What else is there? What am I thinking? So the hardware versus software. So open pilot versus the actual hardware, the device. What's, can you draw that distinction? What's one, what's the other? I mean, the hardware is pretty much a cell phone with a few additions, a cell phone with a cooling system and with a car interface connected to it.

And by cell phone, you mean like Qualcomm Snapdragon? Yeah, the current hardware is a Snapdragon 821. It has a Wi Fi radio, it has an LTE radio, it has a screen. We use every part of the cell phone. And then the interface of the car is specific to the car, so you keep supporting more and more cars. Yeah, through the interface of the car, I mean, the device itself just has four can buses, has four can interfaces on it, they're connected through the USB port to the phone. And then, yeah, on those four can buses, you connect it to the car.

And there's a little harness to do this. Cars are actually surprisingly similar. So can is the protocol by which cars communicate. And then you're able to read stuff and write stuff to be able to control the car, depending on the car. So what's the software side? What's open pilot? So I mean, open pilot is, the hardware is pretty simple compared to open pilot. Open pilot is, well, so you have a machine learning model, which it's an open pilot, it's a blob, it's just a blob of weights. It's not like people are like, oh, it's closed source.

I'm like, what's a blob of weights? What do you expect? It's primarily neural network based. Well, open pilot is all the software kind of around that neural network, that if you have a neural network that says here's where you want to send the car, open pilot actually goes and executes all of that. It cleans up the input to the neural network, it cleans up the output and executes on it. So connects, it's the glue that connects everything together. Runs the sensors, does a bunch of calibration for the neural network, does, deals with like, if the car is on a banked road, you have to counter steer against that.

And the neural network can't necessarily know that by looking at the picture. So you can do that with other sensors, infusion, and localizer, open pilot also is responsible for sending the data up to our servers, so we can learn from it, logging it, recording it, running the cameras, thermally managing the device, managing the disk space on the device, managing all the resources on the device. So what, since we last spoke, I don't remember when, maybe a year ago, maybe a little bit longer, how has open pilot improved? We did exactly what I promised you. I promised you that by the end of the year, we would be able to remove the lanes.

The lateral policy is now almost completely end to end. You can turn the lanes off and it will drive, drive slightly worse on the highway if you turn the lanes off, but you can turn the lanes off and it will drive well trained completely end to end on user data. And this year, we hope to do the same for the longitudinal policy. So that's the interesting thing is you're not doing, you don't appear to be, you can correct me, you don't appear to be doing lane detection or lane marking detection or kind of the segmentation task or any kind of object detection task.

You're doing what's traditionally more called like end to end learning. So entrained on actual behavior of drivers when they're driving the car manually. And this is hard to do. You know, it's not supervised learning. Yeah, but so the nice thing is there's a lot of data, so it's hard and easy, right? We have a lot of high quality data, right? Like more than you need in the center. Well, we've way more than we do. We've way more data than we need. I mean, it's an interesting question, actually, because in terms of amount, you have more than you need.

But the, you know, driving is full of edge cases. So how do you select the data you train on? I think this is an interesting open question. Like, what's the cleverest way to select data? That's the question Tesla is probably working on. That's, I mean, the entirety of machine learning can be, they don't seem to really care. They just kind of select data. But I feel like that if you want to solve, if you want to create intelligence systems, you have to pick data well, right? And so would you have any hints, ideas of how to do it well? So in some ways, that is the definition I like of reinforcement learning versus supervised learning.

In supervised learning, the weights depend on the data, right? And this is obviously true, but in reinforcement learning, the data depends on the weights. Yeah. Right? And actually, both ways. That's poetry. So how does it know what data to train on? Well, let it pick. We're not there yet, but that's the eventual. So you're thinking this almost like a reinforcement learning framework. We're going to do RL on the world. Every time a car makes a mistake, user disengages, we train on that and do RL on the world. Ship out a new model. That's an epoch, right? And for now, you're not doing the Elon style promising that it's going to be fully autonomous.

You really are sticking to level two. And it's supposed to be supervised. It is definitely supposed to be supervised. And we enforce the fact that it's supervised. We look at our rate of improvement in disengagement. OpenPilot now has an unplanned disengagement about every 100 miles. This is up from 10 miles, like maybe a year ago. Yeah. So maybe we've seen 10x improvement in a year, but 100 miles is still a far cry from the 100,000 you're going to need. So you're going to somehow need to get three more 10xs in there. And what's your intuition? You're basically hoping that there's exponential improvement built into the baked into the cake somewhere.

Well, that's even, I mean, 10x improvement, that's already assuming exponential, right? There's definitely exponential improvement. And I think when Elon talks about exponential, like these things, these systems are going to exponentially improve. Just exponential doesn't mean you're getting 100 gigahertz processors tomorrow, right? Like it's going to still take a while because the gap between even our best system and humans is still large. So that's an interesting distinction to draw. So if you look at the way Tesla is approaching the problem, and the way you're approaching the problem, which is very different than the rest of the self driving car world.

So let's put them aside is you're treating most the driving tasks as a machine learning problem. And the way Tesla is approaching it is with the multitask learning, where you break the task of driving into hundreds of different tasks. And you have this multi headed neural network that's very good at performing each task. And there's presumably something on top that's stitching stuff together in order to make control decisions, policy decisions about how you move the car. But what that allows you, there's a brilliance to this because it allows you to master each task, like lane detection, stop sign detection, the traffic light detection, drivable area segmentation, you know, vehicle, bicycle pedestrian detection.

There's some localization tasks in there. Also predicting, like, yeah, predicting how the entities in the scene are going to move. Like everything is basically a machine learning task where there's a classification, segmentation, prediction. And it's nice because you can have this entire engine, data engine that's mining for edge cases for each one of these tasks. And you can have people, like engineers, that are basically masters of that task. They become the best person in the world at, as you talk about the cone guy for Waymo. Yeah, they're a good old cone guy. They become the best person in the world at cone detection.

So that's a compelling notion from a supervised learning perspective, automating much of the process of edge case discovery and retraining neural network for each of the individual perception tasks. And then you're looking at the machine learning in a more holistic way, basically doing end to end learning on the driving tasks, supervised, trained on the data of the actual driving of people they use comma AI, like actual human drivers do manual control, plus the moments of disengagement that maybe with some labeling could indicate the failure of the system. So you have a huge amount of data for positive control of the vehicle, like successful control of the vehicle, both maintaining the lane as I think you're also working on longitudinal control of the vehicle, and then failure cases where the vehicle does something wrong that needs disengagement.

So like what, why do you think you're right and Tesla is wrong on this? And do you think you'll come around the Tesla way? Do you think Tesla will come around to your way? If you were to start a chess engine company, would you hire a bishop guy? See, we have, this is Monday morning quarterbacking is, yes, probably. Oh, our Rook guy. Oh, we stole the Rook guy from that company. Oh, we're going to have real good Rooks. Well, there's not many pieces, right? You can, there's not many guys and gals to hire. You just have a few that work in the bishop, a few that work in the Rook.

But is that not ludicrous today to think about in the world of AlphaZero? But AlphaZero is a chess game, so the fundamental question is how hard is driving compared to chess? Because so long term, end to end will be the right solution. The question is how many years away is that? End to end is going to be the only solution for level five. For the only way we get there. Of course, and of course Tesla is going to come around to my way. And if you're a Rook guy out there, I'm sorry. The Kone guy.

I don't know. We're going to specialize each task. We're going to really understand Rook placement. Yeah, I understand the intuition you have. I mean, that is a very compelling notion that we can learn the task end to end. Like the same compelling notion you might have for natural language conversation. But I'm not sure because one thing you sneaked in there is the assertion that it's impossible to get to level five without this kind of approach. I don't know if that's obvious. I don't know if that's obvious either. I don't actually mean that. I think that it is much easier to get to level five with an end to end approach.

I think that the other approach is doable. But the magnitude of the engineering challenge may exceed what humanity is capable of. So, but what do you think of the Tesla data engine approach, which to me is an active learning task. It's kind of fascinating. It's breaking it down into these multiple tasks and mining their data constantly for like edge cases for these different tasks. Yeah, but the tasks themselves are not being learned. This is feature engineering. I mean, it's a higher abstraction level of feature engineering for the different tasks. It's task engineering in a sense.

It's slightly better feature engineering, but it's still fundamentally is feature engineering. And if anything about the history of AI has taught us anything, it's that feature engineering approaches will always be replaced and lose to end to end. Now, to be fair, I cannot really make promises on timelines, but I can say that when you look at the code for stock fish and the code for alpha zero, one is a lot shorter than the other. A lot more elegant and required a lot less programmer hours to write. Yeah, but there was a lot more murder of bad agents on the alpha zero side.

By murder, I mean agents that played a game and failed miserably. Yeah. Oh, oh. In simulation, that failure is less costly. Yeah. In real world, it's... Do you mean in practice, like alpha zero has lost games miserably? No. Oh, I haven't seen that. No, but I know, but the requirement for alpha zero is to be able to like evolution, human evolution, not human evolution, biological evolution of life on earth from the origin of life has murdered trillions upon trillions of organisms on the path to us humans. So the question is, can we stitch together a human like object without having to go through the entirety process of evolution? Well, no, but do the evolution in simulation? Yeah, that's the question.

Can we simulate? So do you ever sense that it's possible to simulate some aspect of it? Mu zero is exactly this. Mu zero is the solution to this. Mu zero, I think, is going to be looked back as the canonical paper. And I don't think deep learning is everything. I think that there's still a bunch of things missing to get there. But Mu zero, I think, is going to be looked back as the kind of cornerstone paper of this whole deep learning era. And Mu zero is the solution to self driving cars. You have to make a few tweaks to it.

But Mu zero does effectively that. It does those rollouts and those murdering in a learned simulator in a learned dynamics model. It's interesting. It doesn't get enough love. I was blown away when I was blown away when I read that paper. I'm like, you know, OK, I've always had a comma. I'm going to sit and I'm going to wait for the solution to self driving cars to come along. This year I saw it. It's Mu zero. No. So sit back and let the winning roll in. So your sense, just to elaborate a little bit the link on the topic, your sense is neural networks will solve driving.

Yes. Like we don't need anything else. I think the same way chess was maybe the chess and maybe Google are the pinnacle of like search algorithms and things that look kind of like A star. The pinnacle of this era is going to be self driving cars. But on the path that you have to deliver products, and it's possible that the path to full self driving cars will take decades. I doubt it. So how long would you put on it? Like what? What are we? You're chasing it. Tesla is chasing it. What are we talking about? Five years, 10 years, 50 years? Let's say in the 2020s.

In the 2020s. The later part of the 2020s. With the neural network. That would be nice to see. And on the path to that, you're delivering your products, which is a nice L2 system. That's what Tesla is doing, a nice L2 system. It just gets better every time. The only difference between L2 and the other levels is who takes liability. And I'm not a liability guy. I don't want to take liability. I'm going to level two forever. Now, on that little transition, I mean, how do you make the transition work? Is this where driver sensing comes in? Like how do you make the, because you said 100 miles, like, is there some sort of human factor psychology thing where people start to over trust the system? All those kinds of effects.

Once it gets better and better and better and better, they get lazier and lazier and lazier. Is that, like, how do you get that transition right? First off, our monitoring is already adaptive. Our monitoring is already seen adaptive. Driver monitoring. Is this the camera that's looking at the driver? You have an infrared camera in the... Our policy for how we enforce the driver monitoring is seen adaptive. What's that mean? Well, for example, in one of the extreme cases, if the car is not moving, we do not actively enforce driver monitoring. If you are going through like a 45 mile an hour road with lights and stop signs and potentially pedestrians, we enforce a very tight driver monitoring policy.

If you are alone on a perfectly straight highway, and it's all machine learning, none of that is hand coded. Actually, the stop is hand coded, but... So there's some kind of machine learning estimation of risk? Yes. Yeah, I mean, I've always been a huge fan of that. That's difficult to do every step into that direction is a worthwhile stop to take. It might be difficult to do really well. Like, us humans are able to estimate risk pretty damn well. Whatever the hell that is, that feels like one of the nice features of us humans. Because we humans are really good drivers when we're really tuned in.

And we're good at estimating risk, like when are we supposed to be tuned in? Yeah. And people are like, oh, well, why would you ever make the driver monitoring policy less aggressive? Why would you always not keep it at its most aggressive? Because then people are just going to get fatigued from it. Yeah, well, they get annoyed. You know, you know, when they get annoyed, you want the experience to be pleasant. Obviously, I want the experience to be pleasant, but even just from a straight up safety perspective, if you alert people when they look around and they're like, why is this thing alerting me? There's nothing I could possibly hit right now.

People will just learn to tune it out. People will just learn to tune it out, to put weights on the steering wheel, to do whatever, to overcome it. And remember that you're always part of this adaptive system. So all I can really say about how this scale is going forward is, yeah, something we have to monitor for. Ooh, we don't know. This is a great psychology experiment at scale. Like, we'll see. Yeah, it's fascinating. Track it. And making sure you have a good understanding of attention is a very key part of that psychology problem. Yeah, I think you and I probably have a different, come to it differently.

But to me, it's a fascinating psychology problem to explore something much deeper than just driving. It's such a nice way to explore human attention and human behavior, which is why, again, we've probably both criticized Mr. Elon Musk on this one topic from different avenues. So both offline and online, I had little chats with Elon. Like, I love human beings. As a computer vision problem, as an AI problem, it's fascinating. He wasn't so much interested in that problem. It's like, in order to solve driving, the whole point is you want to remove the human from the picture.

And it seems like you can't do that quite yet. Eventually, yes. But you can't quite do that yet. So this is the moment where, and you can't yet say, I told you so, to Tesla, but it's getting there because I don't know if you've seen this. There's some reporting that they're, in fact, starting to do driver monitoring. Yeah, they ship the model in shadow mode. With, though, I believe only a visible light camera. It might even be fisheye. It's like a low resolution. Low resolution visible light. I mean, to be fair, that's what we have in the Eon as well.

Our last generation product. This is the one area where I can say our hardware's ahead of Tesla. The rest of our hardware way, way behind, but our driver monitoring camera. So you think, I think on the third row, Tesla podcast, or somewhere else, I've heard you say that obviously, eventually, they're going to have driver monitoring. I think what I've said is Elon will definitely ship driver monitoring before he ships level five. Level three, four, level five. And I'm willing to bet 10 grand on that. And you bet 10 grand on that. I mean, now I know what to take the bet, but before, maybe someone would have thought, I should have got my money in.

Yeah. It's an interesting bet. I think you're right. I'm actually on a human level, because he's made the decision. Like he said that driver monitoring is the wrong way to go. But you have to think of as a human, as a CEO, I think that's the right thing to say when... Sometimes you have to say things publicly that are different than what you actually believe, because when you're producing a large number of vehicles, and the decision was made not to include the camera, like what are you supposed to say? Yeah. Like, our cars don't have the thing that I think is right to have.

It's an interesting thing, but like on the other side, as a CEO, I mean, something you could probably speak to as a leader, I think about me as a human to publicly change your mind on something. How hard is that? Well, especially when assholes like George Haas say, I told you so. All I will say is I am not a leader, and I am happy to change my mind. You think Elon will? Yeah, I do. I think he'll come up with a good way to make it psychologically okay for him. Well, it's such an important thing, man, especially for a first principles thinker, because he made a decision that driver monitoring is not the right way to go.

And I could see that decision, and I could even make that decision. Like, I was on the fence too. Driver monitoring is such an obvious, simple solution to the problem of attention. It's not obvious to me that just by putting a camera there, you solve things. You have to create an incredible, compelling experience, just like you're talking about. I don't know if it's easy to do that. It's not at all easy to do that, in fact, I think. So, as a creator of a car that's trying to create a product that people love, which is what Tesla tries to do.

Right? It's not obvious to me that as a design decision, whether adding a camera is a good idea. From a safety perspective either, in the human factors community, everybody says that you should obviously have driver sensing, driver monitoring. But that's like saying it's obvious as parents you shouldn't let your kids go out at night. But okay. But they're still going to find ways to do drugs. Yeah. You have to also be good parents. So, it's much more complicated than just you need to have driver monitoring. I totally disagree on, okay, if you have a camera there, and the camera is watching the person, but never throws an alert, they'll never think about it.

Right? The driver monitoring policy that you choose to, how you choose to communicate with the user, is entirely separate from the data collection perspective. Right. Right. So, there's one thing to say, tell your teenager they can't do something. There's another thing to gather the data. So, you can make informed decisions, that's really interesting. But you have to make that, that's the interesting thing about cars. But even true with ComAI, you don't have to manufacture the thing into the car, is you have to make a decision that anticipates the right strategy long term. So, you have to start collecting the data and start making decisions.

It started at three years ago. I believe that we have the best driver monitoring solution in the world. I think that when you compare it to Supercruise, it's the only other one that I really know that shipped, and ours is better. What do you like and not like about Supercruise? I mean, I had a few. Supercruise, the sun would be shining through the window, would blind the camera, and it would say I wasn't paying attention when I was looking completely straight. I couldn't reset the attention with a steering wheel, touch, and Supercruise would disengage. Like, I was communicating to the car, I'm like, look, I'm here, I'm paying attention.

Why are you really going to force me to disengage? And it did. So, it's a constant conversation with the user, and yeah, there's no way to ship a system like this if you can't OTA. We're shipping a new one every month. Sometimes we balance it with our users on Discord. Sometimes we make the driver monitoring a little more aggressive and people complain. Sometimes they don't. We want it to be as aggressive as possible where people don't complain and it doesn't feel intrusive. So, being able to update the system over the air is an essential component.

I mean, that's probably, to me, you mentioned, I mean, to me, that is the biggest innovation of Tesla, that it made it, people realize that over the air updates is essential. Yeah. I mean, was that not obvious from the iPhone? The iPhone was the first real product that OTA'd, I think. Was it actually, that's brilliant, you're right. I mean, the game consoles used to not, right? The game consoles were maybe the second thing that did. Well, I didn't really think about it. One of the amazing features of a smartphone isn't just, like, the touchscreen isn't the thing.

It's the ability to constantly update. Yeah, it gets better. It gets better. I love my iOS 14. Yeah. Well, one thing that I probably disagree with you on, on driver monitoring is you said that it's easy. I mean, you tend to say stuff is easy. I'm sure, I guess you said it's easy relative to the external perception problem there. Can you elaborate why you think it's easy? Feature engineering works for driver monitoring. Feature engineering does not work for the external. So human faces are not, human faces and the movement of human faces and head and body is not as variable as the external environment is your intuition.

Yes, and there's another big difference as well. Your reliability of a driver monitoring system doesn't actually need to be that hot. The uncertainty, if you have something that's detecting whether the human's paying attention and it only works 92% of the time, you're still getting almost all the benefit of that because the human, like, you're training the human, right? You're dealing with a system that's really helping you out. It's a conversation. It's not like the external thing where, guess what? If you swerve into a tree, you swerve into a tree, right? Like, you get no margin for error.

Yeah, I think that's really well put. I think that's the right, exactly the place where we're comparing to the external perception and the control problem. Driver monitoring is easier because you don't, the bar for success is much lower. Yeah, but I still think like the human face is more complicated actually than the external environment. But for driving, you don't give a damn. I don't need something that complicated to have to communicate the idea to the human that I want to communicate, which is, yo, system might mess up here. You got to pay attention. Yeah. See, that's my love and fascination is the human face.

And it feels like this is a nice place to create products that create an experience in the car. So like, it feels like there should be more richer experiences in the car. You know, like that's an opportunity for like something like Kama AI or just any kind of system like a Tesla or any of the autonomous vehicle companies is because software is, there's much more sensors and so much is running on software and you're doing machine learning anyway. There's an opportunity to create totally new experiences that we're not even anticipating. You don't think so? No.

You think it's a box that gets you from A to B and you want to do it chill? Yeah. I mean, I think as soon as we get to level three on highways, okay, enjoy your Candy Crush. Enjoy your Hulu. Enjoy your, you know, whatever, whatever. Sure, you get this. You can look at screens basically versus right now, what do you have? Music and audiobooks. So level three is where you can kind of disengage in stretches of time. Well, you think level three is possible. Like on the highway going for 100 miles and you can just go to sleep? Oh yeah, sleep.

So again, I think it's really all on a spectrum. I think that being able to use your phone while you're on the highway and like this all being okay and being aware that the car might alert you when you have five seconds to basically. So the five second thing that you think is possible? Yeah, I think it is. Oh yeah, not in all scenarios. Some scenarios it's not. It's the whole risk thing that you mentioned is nice is to be able to estimate like how risk is this situation. That's really important to understand. One other thing you mentioned comparing comma and autopilot is that something about the haptic feel of the way comma controls the car when things are uncertain.

Like it behaves a little bit more uncertain when things are uncertain. That's kind of an interesting point and then autopilot is much more confident always even when it's uncertain until it runs into trouble. That's a funny thing. I actually mentioned that to Elon I think and then the first time we talked he was inviting is like communicating uncertainty. I guess comma doesn't really communicate uncertainty explicitly. It communicates it through haptic feel. Like what's the role of communicating uncertainty do you think? We do some stuff explicitly. Like we do detect the lanes when you're on the highway and we'll show you how many lanes we're using to drive with.

You can look at where things the lanes are. You can look at the path. And we want to be better about this when we're actually hiring. We want to hire some new UI people. UI people, you mentioned this. Because it's a UI problem too, right? We have a great designer now but we need people who are just going to build this and debug these UIs. QT people and QT. Is that what the UI has done with this QT? Moving the new UIs and QT. C++ QT. Tesla uses it too. Yeah. Yeah. We had some React stuff in there.

React.js or just React. React has its own language, right? React Native. React Native. React is a JavaScript framework. It's all based on JavaScript. I like C++. What do you think about Dojo with Tesla and their foray into what appears to be specialized hardware for training on that? I guess it's something maybe you can correct me for my shallow looking at it. It seems like something that Google did with TPUs but specialized for driving data. I don't think it's specialized for driving data. It's just legit, just TPU. They want to go the Apple way. Basically everything required in the chain is done in house.

Well, so you have a problem right now and this is one of my concerns. I really would like to see somebody deal with this if anyone out there is doing it. I'd like to help them if I can. You basically have two options right now to train. Your options are Nvidia or Google. So Google is not even an option. Their TPUs are only available in Google Cloud. Google has absolutely onerous terms of service restrictions. They may have changed it but back in Google's terms of service it said explicitly you are not allowed to use Google Cloud ML for training autonomous vehicles or for doing anything that competes with Google without Google's prior written permission.

I mean Google is not a platform company. I wouldn't touch TPUs with a 10 foot pole. So that leaves you with the monopoly. In video. In video. Yeah. So I mean. That you're not a fan of. Well look I was a huge fan of in 2016 Nvidia. Jensen came sat in the car. Cool guy when the stock was $30 a share. Nvidia stock has skyrocketed. I witnessed a real change and who was in management over there in like 2018. And now they are let's exploit. Let's take every dollar we possibly can out of this ecosystem.

Let's charge $10,000 for A100s because we know we got the best shit in the game. And let's charge $10,000 for an A100 when it's really not that different from a 3080 which is $699. The margins that they are making off of those high end chips are so high that I mean I think they're shooting themselves in the foot just from a business perspective because there's a lot of people talking like me now who are like somebody's got to take Nvidia down. Yeah where they could dominate. Nvidia could be the new Intel. Yeah to be inside everything essentially and yet the winners in certain spaces like in autonomous driving the winners only the people who are like desperately falling back and trying to catch up and have a ton of money like the big automakers are the ones interested in partnering with Nvidia.

Oh and I think a lot of those things are going to fall through. If I were Nvidia sell chips. Sell chips at a reasonable markup. To everybody. To everybody. Without any restrictions. Without any restrictions. Intel did this. Look at Intel. They had a great long run. Nvidia is trying to turn their they're like trying to productize their chips way too much. They're trying to extract way more value than they can sustainably. Sure you can do it tomorrow. Is it going to up your share price? Sure if you're one of those CEOs is like how much can I strip mine this company and you know and that's what's weird about it too.

Like the CEO is the founder. It's the same guy. Yeah. I mean I still think Jensen's a great guy. He is great. Why do this? You have a choice. You have a choice right now. Are you trying to cash out? Are you trying to buy a yacht? If you are fine. But if you're trying to be the next huge semiconductor company sell chips. Well the interesting thing about Jensen is he is a big vision guy. So he has a plan like for 50 years down the road. So it makes me wonder like. How does price gouging fit into it? Yeah how does that like it's it doesn't seem to make sense as a plan.

I worry that he's listening to the wrong people. Yeah that that's the sense I have too sometimes because I despite everything I think NVIDIA is an incredible company. Well one I'm deeply grateful to NVIDIA for the products they've created in the past. Me too. Right. And so. The 1080Ti was a great GPU. Still have a lot of them. Still is yeah. But at the same time it just feels like. Feels like you don't want to put all your stock in NVIDIA. And so the Elon is doing what Tesla is doing with autopilot and Dojo is the Apple way is because they're not going to share Dojo.

With George Hott's. I know they should sell that chip. Oh they should sell that even their their accelerator. The accelerator that's in all the cars the 30 watt one. Sell it why not. So open it up. Make me why does this has to be a car company. Well if you sell the chip here's what you get. Yeah. Makes the money all the chips. It doesn't take away from your chip. You're going to make some money free money. And also the world is going to build an ecosystem of tooling for you. Right. You're not going to have to fix the bug in your 10H layer.

Someone else already did. Well the question that's an interesting question. I mean that's the question Steve Jobs asked. That's the question Elon Musk is perhaps asking is do you want Tesla stuff inside other vehicles in inside potentially inside like iRobot Vacuum Cleaner. Yeah. I think you should decide where your advantages are. I'm not saying Tesla should start selling battery packs to to automakers because battery packs to automakers they're straight up in competition with you. If I were Tesla I'd keep the battery technology totally. Yeah. As far as we make batteries. But the thing about the Tesla TPU is anybody can build that.

It's just a question of you know are you willing to spend the you know the money. It could be a huge source of revenue potentially. Are you willing to spend 100 million dollars. Right. Anyone can build it. And someone will. And a bunch of companies now are starting trying to build AI accelerators. Somebody's going to get the idea right. And yeah. Hopefully they don't get greedy because they'll just lose to the next guy who finally and then eventually the Chinese are going to make knockoff and video chips and that's. From your perspective I don't know if you're also paying attention to Stan Tesla for a moment.

Dave Elon Musk has talked about a complete rewrite of the neural net that they're using that seems to again I'm half paying attention. But it seems to involve basically a kind of integration of all the sensors to where it's a four dimensional view you know you have a 3D model of the world over time. And then you can I think it's done both for the for the actually you know so the neural network is able to in a more holistic way deal with the world and make predictions and so on. But also to make the annotation task more you know easier like you can annotate the world in one place and they kind of distribute itself across the sensors and across a different like the hundreds of tasks that are involved in the hydranet.

What are your thoughts about this rewrite is it just like some details that are kind of obvious that are steps that should be taken or is there something fundamental that could challenge your idea that end to end is the right solution. We're in the middle of a big rewrite now as well we haven't shipped a new model in a bit. Of what kind? We're going from 2D to 3D. Right now all our stuff like for example when the car pitches back the lane lines also pitch back because we're assuming the flat world hypothesis the new models do not do this the new models output everything in 3D.

But there's still no annotation so the 3D is it's more about the output. We have Z's in everything. We've had a disease. We unified a lot of stuff as well. We switched from TensorFlow to PyTorch. My understanding of what Tesla's thing is is that their annotator now annotates across the time dimension. I mean cute. Why are you building an annotator? I find their entire pipeline. I find your vision I mean the vision of end to end very compelling but I also like the engineering of the data engine that they've created. In terms of supervised learning pipelines that thing is damn impressive.

You're basically the idea is that you have hundreds of thousands of people that are doing data collection for you by doing their experience so that's kind of similar to the Kama AI model and you're able to mine that data based on the kind of education you need. I think it's harder to do in the end to end learning. The mining of the right edge case. That's what feature engineering is actually really powerful because us humans are able to do this kind of mining a little better. But yeah there's obvious constraints and limitations to that idea.

Carpathia just tweeted. He's like you get really interesting insights if you sort your validation set by loss and look at the highest loss examples. Yeah. So yeah I mean you can do we have we have a little data engine like thing we're training a segnat anyway it's not fancy it's just like okay train the new segnat run it on a hundred thousand images and now take the thousand with highest loss select a hundred of those by human put those get those ones labeled retrain do it again. So it's a much less well written data engine and yeah you can take these things really far and it is impressive engineering and if you truly need supervised data for a problem yeah things like data engine are the high end of what is attention is a human paying attention.

I mean we're going to probably build something that looks like data engine to push our driver monitoring further but for driving itself you have it all annotated beautifully by what the human does so. Yeah that's interesting I mean that applies to driver attention as well. Do you want to detect the eyes do you want to detect blinking and pupil movement do you want to detect all the like a face alignment so landmark detection and so on and then doing kind of reasoning based on that or do you want to take the entirety of the face over time and do end to end.

I mean it's obvious that over eventually you have to do end to end with some calibration with some fixes and so on but it's like I don't know when that's the right move. Even if it's end to end there actually is there is no kind of um you have to supervise that with humans. Whether a human is paying attention or not is a completely subjective judgment um like you can try to like automatically do it with some stuff but you don't have if I record a video of a human I don't have true annotations anywhere in that video.

The only way to get them is with you know other humans labeling it really. Well I don't know you so if you think deeply about it you could you might be able to just depending on the task you may be a discover self annotating things like you know you can look at like steering wheel reverse or something like that. You can discover little moments of lapse of attention. Yeah I mean that's that's where psychology comes in is there indicate because you have so so much data to look at so you might be able to find moments when there's like just inattention that even with smartphone if you want to text smartphone use yeah you can start to zoom in I mean that's the goldmine a sort of the comma AI I mean Tesla's doing this too right is there they're doing annotation based on it's like uh self supervised learning too it's just a small part of the entire picture it's that's kind of the challenge of solving a problem in machine learning if you can discover self annotating parts of the problem right.

Our driver monitoring team is half a person right now half a person you know once we have skill to a full once we have two people once we have two three people on that team I definitely want to look at self annotating stuff for attention. Let's go back for a sec to to a comma and what you know for people who are curious to try it out how do you install a comma in say a 2022 or a Corolla or like what are the cars that are supported what are the cars that you recommend and what does it take you have a few videos out but maybe through words can you explain now what's it take to actually install a thing.

So we support I think it's 91 cars 91 makes models you get to 100 this year. Nice. The yeah the 2020 Corolla great choice the 2020 Sonata it's using the stock longitudinal it's using just our lateral control but it's a very refined car their longitudinal control is not bad at all. So yeah Corolla Sonata or if you're willing to get your hands a little dirty and look in the right places on the internet the Honda Civic is great but you're going to have to install a modified EPS firmware in order to get a little bit more torque and I can't help you with that comma does not efficiently endorse that but we have been doing it we didn't ever release it we waited for someone else to discover it and then you know.

And you have a discord server where people there's a very active developer community I suppose so depending on the level of experimentation you're willing to do that's a community. If you if you just want to buy it and you have a supported car yeah it's 10 minutes to install there's YouTube videos it's Ikea furniture level if you can set up a table from Ikea you can install a comma two in your supported car and it will just work now you're like oh but I want this high end feature or I want to fix this bug okay well welcome to the developer community.

So what if I wanted to this is something I asked you I'll find like a few months ago if I wanted to run my own code to so use comma as a platform and try to run something like open pilot what does it take to do that? So there's a toggle in the settings called enable ssh and if you toggle that you can ssh into your device you can modify the code you can upload whatever code you want to it. There's a whole lot of people so about 60% of people are running stock comma about 40% of people are running forks and there's a community of there's a bunch of people who maintain these forks and these forks support different cars or they have you know different toggles we try to keep away from the toggles that are like disabled driver monitoring but you know there's some people might want that kind of thing and like you know yeah you can it's your car it's your I'm not here to tell you you know we have some you know we ban if you're trying to subvert safety features you're banned from our discord I don't want anything to do with you but there's some forks doing that.

Got it. So you encourage responsible forking. Yeah yeah we encourage some people you know yeah some people like like there's forks that will do some people just like having a lot of readouts on the UI like a lot of like flashing numbers so there's forks that do that. Some people don't like the fact that it disengages when you press the gas pedal there's forks that disable that. Got it. Now the the stock experience is is what like so it does both lane keeping and longitudinal control all together so it's not separate like it is an autopilot.

No so okay some cars we use the stock longitudinal control we don't do the longitudinal control in all the cars. Some cars the ACC's are pretty good in the cars it's the lane keep that's atrocious in anything except for autopilot and supercruise. But you know you just turn it on and it works what does this engagement look like? Yeah so we have I mean I'm very concerned about mode confusion I've experienced it on supercruise and autopilot where like autopilot like autopilot disengages I don't realize that the ACC is still on the lead car moves slightly over and then the Tesla accelerates to like whatever my set speed is super fast and like what's going on here.

We have engaged and disengaged and this is similar to my understanding I'm not a pilot but my understanding is either the pilot is in control or the copilot is in control and we have the same kind of transition system either open pilot is engaged or open pilot is disengaged engage with cruise control disengage with either gas break or cancel. Let's talk about money what's the business strategy for comma profitable well it's your you did it congratulations what so it's basically selling we should say comma cost a thousand bucks comma two two hundred for the interface to the car as well it's 1200 I'll send that nobody's usually up front like this you gotta add the tack on right yeah I love it this I'm not gonna lie to you trust me it will add 1200 a value to your life yes it's still super cheap 30 days no questions asked money back guarantee and prices are only going up you know if there ever is future hardware it costs a lot more than 1200 dollars so comma three is in the works so it could be all I all I will say is future hardware is going to cost a lot more than the current hardware yeah like the people that use the people have spoken with that use comma they use open pilot they first of all they use it a lot so people that use it they they fall in love with oh our retention rate is insane there's a good sign yeah it's a really good sign um 70 percent of comma two buyers are daily active users yeah it's amazing um oh also we don't plan on stopping selling the comma two like like it's you know so whatever you create that's beyond comma two it would be uh it would be potentially a phase shift like it's it's so much better that like you could use comma two and you can use comma whatever depends what you want it's kind of 41 42 yeah you know autopilot hardware one versus hardware two the comma two is kind of like hardware one got it got it you can still use both got it got it I think I heard you talk about retention rate with uh BR headsets that the average is just once yeah just fast I mean it's such a fascinating way to think about technology and this is a really really good sign and the other thing that people say about comma is like they can't believe they're getting this four thousand bucks right it's it seems it seems like some kind of steal so but in terms of like long term business strategies that basically to put so it's currently in like a thousand plus cars uh 1200 more uh so yeah dailies is about uh dailies is about 2000 weekly is about 2500 monthly is over 3000 wow we've grown a lot since we last talked is the goal that can we talk crazy for a second I mean what's the the goal to overtake tesla let's talk okay so I mean android did overtake ira that's exactly it right so they did it I actually don't know the timeline of that one they but let let let's talk uh because everything is in alpha now the autopilot you could argue is in alpha in terms of towards the big mission of autonomous driving right and so what yeah it's your goal to overtake to get millions of cars essentially of course where would it stop like it's open source software it might not be millions of cars with a piece of comma hardware but yeah I think open pilot at some point will cross over autopilot in in in users just like android crossed over ios how does google make money from android uh it's it's complicated their own devices make money google google makes money by just kind of having you on the internet uh yes google search is built in gmail is built in android is just a shield for the rest of google's ecosystem kind yeah but the problem is android is not is a brilliant thing i mean android arguably changed the world so there you go that's you can you can feel good ethically speaking but as a business strategy it's questionable oh so hardware so hardware i mean it took google a long time to come around to it but they are now making money on the pixel you're not about money you're more about winning yeah but if only if only 10 percent of open pilot devices come from comma ai we still make a lot that is still yes that is a ton of money for our company but can't somebody create a better comma using open pilot or you're basically saying we'll outcompete them well i'll compete you is can you create a better android phone than the google pixel right i mean you can but like i love that so you're confident like you know what the hell you're doing yeah it's it's uh uh competence and merit i mean our money our money comes from we're consumer electronics company yeah and put it this way so we sold we sold like 3 000 comma twos um i mean 2500 right now uh and like okay we're probably gonna sell 10 000 units next year right 10 000 units and even just a thousand dollars a unit okay we're at 10 million in uh in in revenue um get that up to a hundred thousand maybe double the price of the unit now we're talking like 200 million revenue yeah actually making money one of the rare semi autonomous autonomous vehicle companies that are actually making money yeah yeah you know if you have if you look at a model when we were just talking about this yesterday if you look at a model and like you're testing like your ab testing your model and if your your your one branch of the ab test the losses go down very fast in the first five epochs yeah that model is probably going to converge to something considerably better than the one with the losses going down slower why do people think this is going to stop why do people think one day there's going to be a great like well waymo's eventually going to surpass you guys oh they're not do you see like a world where like a tesla or a car like a tesla would be able to basically press a button and you like switch to open pilot you know you you know they've load in i don't know so i think so first off i think that we may surpass tesla in terms of users i do not think we're going to surpass tesla ever in terms of revenue i think tesla can capture a lot more revenue per user than we can but this mimics the android ios model exactly there may be more android devices but you know there's a lot more iphones than google pixels so i think there'll be a lot more tesla cars sold than pieces of comma hardware um and then as far as a tesla owner being able to switch to open pilot uh does ios does iphones run android no but you can if you really want to do it but it doesn't really make sense like it's not it doesn't make sense who cares what about if uh a large company like automakers for GM Toyota came to george hots or on the tech space amazon facebook google came with a large pile of cash uh would would you consider being um purchased what did you see that as a one possible not seriously no um i would probably uh see how much uh shit they'll entertain for me um and if they're willing to like jump through a bunch of my hoops then maybe but like no not the way that mna works today i mean we've been approached and i laugh in these people's faces i'm like are you kidding yeah you know because it's so it's so it's so demeaning the mna people are so demeaning to companies they treat the startup world as their innovation ecosystem and they think that i'm cool with going along with that so i can have some of their scam fake fed dollars you know fed coin i'm what am i gonna do with more fed coin you know head coin fed coin man i love that so that's the cool thing about podcasting actually is uh people criticize i don't know if you're familiar with uh less spotify uh giving joe rogan a hundred million i'd talk about that and you know they respect despite all the shit that people are talking about spotify people understand that podcasters like joe rogan know what the hell they're doing yeah so they give them money and say just do what you do and like the equivalent for you would be like george do what the hell you do because you're good at it try not to murder too many people like try like there's some kind of common sense things like just don't go on a weird rampage of yeah it comes down to what companies i could respect right um you know could i respect gm never um no i couldn't i mean could i respect like a hundai more some right that's that's a lot closer to yoda what's your nah no it's like the korean is the way i think i think that you know the japanese the germans the u.s

they're all too they're all too you know they all think they're too great to be about the tech companies apple apple is of the tech companies that i could respect apples the closest yeah i mean i could never should be ironic would be ironic oh if if kama ai is uh is acquired by apple i mean facebook look i quit facebook 10 years ago because i didn't respect the business model um google has declined so fast in the last five years what are your thoughts about wemo and its present and its future is let me let me say let me start by saying something uh nice which is uh i've visited them a few times and i've uh have written in their cars and the engineering that they're doing both the research and the actual development and the engineering they're doing and the scale they're actually achieving by doing it all themselves is really impressive and the the balance of safety and innovation and like the cars work really well for the routes they drive like they drive fast which was very surprising to me like it drives like the speed limit or faster the speed limit is it goes and it works really damn well and the interface is nice and channel or zone yeah yeah and channel there's a very specific environment so it i you know it gives me enough material in my mind to push back against the madman of the world like george hotz to be like because you kind of imply there's zero probability they're going to win yeah and after i've used after i've written in it to me it's not zero oh it's not for technology reasons bureaucracy no it's worse than that it's actually for product reasons i think oh you think they're just not capable of creating an amazing product uh no i think that the product that they're building doesn't make sense um so a few things uh you say the waymos are fast um benchmark a waymo against a competent uber driver right the uber driver is faster it's not even about speed it's the thing you said it's about the experience of being stuck at a stop sign because pedestrians are crossing nonstop that i like when my uber driver doesn't come to a full stop at the stop sign yeah you know and so let's say the waymos are 20 slower than than an uber right um you can argue that they're going to be cheaper and i argue that users already have the choice to trade off money for speed it's called uber pool um i think it's like 15 percent of rides at uber pools right users are not willing to trade off money for speed so the whole product that they're building is not going to be competitive with traditional ride sharing networks right um like and also whether there's profit to be made depends entirely on one company having a monopoly i think that the level for autonomous ride sharing vehicles market is going to look a lot like the scooter market if even the technology does come to exist which i question who's doing well in that market yeah it's a race to the bottom you know well they could be it could be closer like an uber in a lift where it's just a one or two players well the scooter people have given up trying to market scooters as a practical means of transportation and they're just like they're super fun to ride look at wheels i love those things and they're great on that front yeah but from an actual transportation product perspective i do not think scooters are viable and i do not think level four autonomous cars are viable if you uh let's play a fun experiment if you ran let's do uh tesla and let's do waymo if uh ilan musk took a vacation for a year he just said screw it i'm gonna go live in an island no electronics and the board decides that we need to find somebody to run the company and they they decide that you should run the company for a year how do you run tesla differently i wouldn't change much do you think they're on the right track i wouldn't change i mean i'd have some minor changes but even even my debate with tesla about you know end to end versus segnets like that's just software who cares right like it's not gonna it's not like you're doing something terrible with segnets you're probably building something that's at least going to help you debug the end to end system a lot right it's very easy to transition from what they have to like an end to end kind of thing right uh and then i presume you would uh in the model y or maybe in the model three start adding driver sensing with infrared yes i would add i would add i would add infrared camera infrared lights right away to those cars um and start collecting that data and do all that kind of stuff yeah very much i think they're already kind of doing it it's it's an incredibly minor change if i actually were to have tesla first off i'd be horrified that i wouldn't be able to do a better job as elon and then i would try to you know understand the way he's done things before you would also have to take over his twitter so i don't tweet yeah what's your twitter situation why why why are you so quiet on twitter i mean du comma is like what what's your social network presence like because you on instagram you're you uh you do live streams you're you're you're um you understand the music of the internet but you don't always fully engage into it you're part time why you still have a twitter yeah i mean it's the instagram is a pretty place instagram is a beautiful place it glorifies beauty i like i like instagram's values as a network got um twitter glorifies conflict quarter glorifies you know like like like like like you know just shots taking shots of people and it's like you know you know twitter and donald trump are perfectly perfect for each other so teslas on uh teslas on the right track in your view yeah okay so let's try let's like really try this experiment if you ran waymo let's say they're i don't know if you agree but they seem to be at the head of the pack of the kind of uh what would you call that approach like it's not necessarily lighter based because it's not about lighter level four robotaxi level four robotaxi all in before any before making any revenue uh so they're probably at the head of the pack if you were said uh hey george can you please run this company for a year how would you change it uh i would go i would get anthony levandowski out of jail and i would put him in charge of the company um let's try to break that apart one do you want to make you want to destroy the company by doing that or do you mean or do you mean uh you like renegade style thinking that pushes that that like throws away bureaucracy and goes to first principle thinking what what do you mean by that um i think anthony levandowski is a genius and i think he would come up with a much better idea of what to do with waymo than me so you mean that unironically he is a genius oh yes oh absolutely without a doubt i mean i'm not saying there's no shortcomings but in the interactions i've had with him yeah what um he's also willing to take like who knows what he would do with waymo i mean he's also out there like far more out there than i am yeah his big risks yeah what do you make of him i was i was going to talk to him in his pockets and i was going back and forth i'm such a gullible naive human like i see the best in people and i slowly started to realize that there might be some people out there that like have multiple faces to the world they're like deceiving and dishonest i still refuse to like i i just i trust people and i don't care if i get hurt by it but like you know sometimes you have to be a little bit careful especially platform wise and podcast wise what are you what am i supposed to think so you think you think he's a good person oh i don't know i don't really make moral judgments it's difficult to all i mean this about the waymo i actually i mean that whole idea very non ironically about what i would do the problem with putting me in charge of waymo is waymo is already 10 billion dollars in the hall right whatever idea waymo does look comma's profitable comma's raised 8.1

million dollars that's small you know that's small money like i can build a reasonable consumer electronics company and succeed wildly at that and still never be able to pay back waymo's 10 billion so i i think the basic idea with waymo will forget the 10 billion because they have some backing but your basic thing is like what can we do to start making some money well no i mean my bigger idea is like whatever the idea is that's going to save waymo i don't have it it's going to have to be a big risk idea and i cannot think of a better person than anthony levendowski to do it so that is completely what i would do ceo of waymo i would call myself a transitionary ceo do everything i can to fix that situation up yeah uh yeah because i can't i can't do it right like i can't i can't i mean i can talk about how what i really want to do is just apologize for all those corny uh you know ad campaigns and be like here's the real state of the technology yeah that's like i have several criticism i'm a little bit more bullish on waymo than than you seem to be but one criticism i have is it went into corny mode too early like it's still a startup it hasn't delivered on anything so it should be like more renegade and show off the engineering that they're doing which just can be impressive as opposed to doing these weird commercials of like your friendly your friendly car company i mean that's my biggest my biggest snipe at waymo was always that guy's a paid actor that guy's not a waymo user he's a paid actor look here i found his call sheet do kind of like what spacex is doing with the rocket launch is just get put the nerds up front put the engineers up front and just like show failures too just i love i love spacex is yeah yeah the thing they're doing it is right and it just feels like the right but we're all so excited to see them succeed yeah i can't wait to see waymo fail you know like you lie to me i want you to fail you tell me the truth you be honest with me i want you to succeed yeah yeah uh yeah and that requires the uh the renegade ceo right i'm with you i'm with you i still have a little bit of faith in waymo to for for the renegade ceo to step forward but it's not it's not john kraftzak yeah it's uh you can't it's not Chris homestead and i'm those people may be very good at certain things yeah but they're not renegades yeah because these companies are fundamentally even though we're talking about billion dollars all these crazy numbers they're still like early stage startups i mean and i i just i if you are pre revenue and you've raised 10 billion dollars i have no idea like like this just doesn't work you know it's against everything silicon valley where's your minimum viable product you know where's your users was your growth numbers this is traditional silicon valley why do you not apply it to what you think you're too big to fail already like how do you think autonomous driving will change society so the mission is for comma to solve self driving do you have like a vision of the world of how it'll be different is it as simple as a to b transportation or is there like because these are robots it's not about autonomous driving in and of itself it's what the technology enables it's i think it's the coolest applied ai problem i like it because it has a clear path to monetary value um but as far as that being the thing that changes the world i mean no like like there's cute things we're doing in common like who'd have thought you could stick a phone on the windshield and it'll drive um but like really the product that you're building is not something that people were not capable of imagining 50 years ago so no it doesn't change the world on that front could people have imagined the internet 50 years ago only true junior genius visionaries yeah everyone could have imagined autonomous cars 50 years ago it's like a car but i don't drive it see i i have the sense and i told you like i'm my long term dream is robots with which you have deep with whom you have deep connections right and uh there's different trajectories towards that and i've been thinking so been thinking of launching a startup i see autonomous vehicles as a potential trajectory to that that that i'm that's not where the direction i would like to go but i also see tesla or even kama ai like pivoting into into robotics broadly defined that's at some stage in the way like you're mentioning the internet didn't expect let's solve you know what i say a comma about this we could talk about this but let's solve self driving guys first gotta stay focused on the mission don't don't don't you're not too big to fail for however much i think calm is winning like no no no no you're winning when you solve level five self driving cars and until then you haven't won and won and you know again you want to be arrogant in the face of other people great you want to be arrogant in the face of nature you're an idiot right stay mission focused brilliantly put uh like i mentioned thinking of launching a startup i've been considering actually before covid i've been thinking of moving to san francisco oh i wouldn't go there so why is uh well and now i'm thinking about potentially austin and we're in san diego now san diego come here so why what um i mean you're you're such an interesting human you've launched so many successful things what uh why san diego what do you recommend why not san francisco have you thought well so in your case san diego with qualcomm is now dragon i mean that's an amazing combination but that wasn't really why that wasn't the why no i mean qualcomm was an afterthought qualcomm was it was a nice thing to think about it's like you can have a tech company here and a good one i mean you know i like qualcomm but no um well so why san diego better than san francisco why does san francisco suck well so okay so first off we all kind of said like we want to stay in california people like the ocean you know california for for its flaws it's like a lot of the flaws of california are not necessarily california as a whole and they're much more san francisco specific yeah um san francisco so i think first year cities in general have stopped wanting growth uh well you have like in san francisco you know the voting class always votes to not build more houses because they own all the houses and they're like well you know once people have figured out how to vote themselves more money they're going to do it it is so insanely corrupt um it is not balanced at all like political party wise you know it's it's it's a one party city and for all the discussion of diversity yeah it's has it stops lacking real diversity of thought of background of uh approaches the strategies of yeah ideas it's it's kind of a strange place that it's the loudest people about diversity and the biggest lack of diversity well i mean that's that's what they say right it's the projection projection yeah yeah it's interesting and even people in silicon valley tell me that's uh like high up people that everybody is like this is a terrible place it doesn't make i mean and coronavirus is really what killed it yeah uh san francisco was the number one uh exodus during coronavirus we still think san diego's uh is a good place to be yeah yeah i mean we'll see we'll see what happens with california a bit longer term yeah like austin's and austin's an interesting choice i wouldn't i wouldn't i don't really anything bad to say about austin either except for the extreme heat in the summer um which you know but that's like very on the surface right i think as far as like an ecosystem goes it's it's cool i personally love colorado colorado is great uh yeah i mean you have these states that are you know like just way better run um california is you know it's especially san francisco it's on its high horse and like yeah can i ask you for advice to me and to others about what's the take to build a successful startup oh i don't know i haven't done that talk to someone who did that well you've you know uh this is like another book of years i'll buy for sixty seven dollars i suppose uh so there's um one of these days i'll sell out yeah that's right jail breaks are going to be a dollar and books are going to be 67 how i uh how i jail broke the iphone by george hotz that's right how i jail broke the iphone and you can do you can't do 67 in in 21 days that's right that's right oh god okay i can't wait but quite so you haven't introspected you have built a very unique company i mean not not you but you and others but i don't know um there's no there's nothing you haven't introspect you haven't really sat down and thought about like well like if you and i were having a bunch of we're having some beers and you're seeing that i'm depressed and whatever i'm struggling there's no advice you can give oh i mean more beer more beer yeah i think it's all very like situation dependent um here's okay if i can give a generic piece of advice it's the technology always wins the better technology always wins and lying always loses build technology and don't lie i'm with you i agree very much the long run long run sure it's the long run you know what the market can remain irrational longer than you can remain solvent true fact well this is this is an interesting point because i ethically and just as a human believe that um like like hype and smoke and mirrors is not at any stage of the company is a good strategy i mean there's some like you know pr magic kind of like you know you want a new product yeah if there's a call to action if there's like a call to action like buy my new gpu look at it it takes up three slots and it's this big it's huge buy my gpu yeah that's great if you look at you know especially in that in ai space broadly but autonomous vehicles like you can raise a huge amount of money on nothing and the question to me is like i'm against that i'll never be part of that i don't think i hope not willingly not but like is there something to be said to uh essentially lying to raise money like fake it till you make a kind of thing i mean this is billy mcfardle in the fire festival like we all we all experienced uh you know what happens with that no no don't fake it till you make it be honest and hope you make it the whole way the technology wins right the technology wins and like there is i'm not i use like the anti hype you know that's that's a slava kpss reference but um hype isn't necessarily bad i loved camping out for the iphones um you know and as long as the hype is backed by like substance as long as it's backed by something i can actually buy and like it's real then hype is great and it's a great feeling it's when the hype is backed by lies that it's a bad feeling i mean a lot of people call you on musk a fraud how could it be a fraud i've noticed this this kind of interesting effect which is he does tend to over promise and deliver what's what's the better way to phrase it promise a timeline that he doesn't deliver on he delivers much later on what do you think about that because i i do that i think that's a programmer thing yeah i do that as well you think that's a really bad thing to do is is that okay i think that's again as long as like you're working toward it and you're gonna deliver on and it's not too far off right yeah right like like you know the whole the whole autonomous vehicle thing it's like i mean i still think tassel is on track to to beat us i still think even with their even with their missteps they have advantages we don't have um you know elon is is better than me at at at like marshalling massive amounts of resources so you know i still think given the fact they're maybe making some wrong decisions they'll end up winning and like it's fine to hype it if you're actually gonna win right like if elon says look we're gonna be landing rockets back on earth in a year and it takes four like you know he landed a rocket back on earth and he was working toward it the whole time i think there's some amount of like i think what it becomes wrong is if you know you're not gonna meet that deadline if you're lying yeah that's brilliantly put like this is what people don't understand i think like elon believes everything he says he does as far as i can tell he does and i i detected that in myself too like if i it's only bullshit if you if you're like conscious of yourself lying yeah i think so yeah no you can't take that to such an extreme right like in a way i think maybe billy mcfarland believed everything he said too right that's how you start a cult and and everybody uh kills themselves yeah yeah like it's you need you need if there's like some factor on it it's fine and you need some people to like you know keep you in check but like if you deliver on most of the things you say and just the timelines are off man it does piss people off though i wonder but who cares in in a long arc of history the people everybody gets pissed off at the people who succeed which is one of the things that frustrates me about this world is um they don't celebrate the success of others like there's so many people that want elon to fail it's so fascinating to me like what is wrong with you like so elon most talks about like people it's short like they talk about financial but i think it's much bigger than the financials i've seen like the human factors community be they want they want other people to fail why why why like even people the harshest thing is like you know even people that like seem to really hate donald trump they want him to fail or like the other president or they want rock obama to fail it's like it's weird but i i want that i would love to inspire that part of the world to change because well dammit if the human species is going to survive we can celebrate success like it seems like the efficient thing to do in this objective function that like we're all striving for is to celebrate the ones that like figure out how to like do better at that objective function as opposed to like dragging them down back into them into the mud i think there is this is the speech i always give about the commenters on hacker news um so first off something to remember about the internet in general is commenters are not representative of the population yeah i don't comment on anything i don't you know commenters are are are representative of a a certain sliver of the population and on hacker news a common thing i'll see is when you'll see something that's like you know promises to be wild out there and innovative there is some amount of you know know checking them back to earth but there's also some amount of if this thing succeeds well i'm 36 and i've worked at large tech companies my whole life they can't succeed because if they succeed that would mean that i could have done something different with my life but we know that i couldn't have we know that i couldn't have and and that's why they're gonna fail and they have to root for them to fail to kind of maintain their world image so tune it out and they comment well it's hard i so one of the things one of the things i'm considering startup wise is to change that because i think the i think it's also a technology problem it's a platform problem i agree it's like because the thing you said most people don't comment it i think most people want to comment they just don't because it's all the assholes for commenting i don't want to be grouped in with them i'm not you don't want to be at a party where everyone is an asshole and so they but that's a platform's problem that's i can't believe what reddits become i can't believe the group thinking reddit comments there's a reddit is interesting one because they're subreddits and so you can still see especially small subreddits that like that are little like havens of like joy and positivity and like deep even disagreement but like nuanced discussion but it's only like small little pockets but that's that's emergent the platform is not helping that or hurting that so i guess naturally something about the internet that if you don't put in a lot of effort to encourage nuance and positive good vibes it's naturally going to decline into chaos i would love to see someone do this well yeah i think it's yeah very doable this is i think actually so i feel like twitter could be overthrown yeah ashwabak talked about how like uh if you have like and retweet like that's only positive wiring right the only way to do anything like negative there is um with a comment and that's like that asymmetry is what gives you know twitter its particular toxicness whereas i find youtube comments to be much better because youtube comments have a have a have an up and a down and they don't show the downloads without getting into depth of this particular discussion the point is to explore possibilities and get a lot of data on it because uh i mean i could disagree with what you just said it's the point is it's unclear it's a it hasn't been explored in a really rich way uh like these questions of how to create platforms that encourage positivity yeah i think it's a it's a technology problem and i think we'll look back at twitter as it is now maybe it'll happen within twitter but most likely somebody overthrows them is we'll look back at twitter and and say we can't believe we put up with this level of toxicity you need a different business model too any any social network that fundamentally has advertising as a business model this was in the social dilemma which i didn't watch but i liked it it's like you know there's always the you know you're the product you're not the uh but they had a nuance take on it that i really liked and it said the product being sold is influence over you the product being sold is literally your you know influence on you like that can't be if that's your idea okay well you know guess what it can't not be toxic yeah maybe there's ways to spin it like with with giving a lot more control to the user and transparency to see what is happening to them as opposed to in the shadows as possible but that can't be the primary source but the users aren't no one's going to use that it depends it depends it depends i think i think that the you're you're not going to you can't depend on self awareness of the users it's a it's another it's a longer discussion because uh you can't depend on it but you can reward self awareness like if for the ones who are willing to put in the work of self awareness you can reward them and incentivize and perhaps be pleasantly surprised how many people are willing to be self aware on the internet like we are in real life like i'm putting in a lot of effort with you right now being self aware about if i say something stupid or mean i'll like look at your like body language like i'm putting in that effort it's costly for an intro very costly but on the internet fuck it like most people are like i don't care if this hurts somebody i don't care if this uh is not interesting or if this is yeah the mean or whatever i think so much of the engagement today on the internet is so disingenuine too yeah you're not doing this out of a genuine this is what you think you're doing this just straight up to manipulate others whether you're in you just became an ad okay let's talk about a fun topic which is programming here's another book idea for you let me pitch uh what's your uh perfect programming setup so like this by george hotz so uh like what listen your give me give me a mac book air sit me in a corner of a hotel room and you know i'll still ask so you really don't care you don't fetishize like multiple monitors keyboard uh those things are nice and i'm not going to say no to them but do they automatically unlock tons of productivity no not at all i have definitely been more productive on a mac book air in a corner of a hotel room what about um ide so uh which operating system do you love what uh text editor do you use ide what um is there is there something that that is like the perfect if you could just say the perfect productivity setup for george hotz doesn't matter doesn't it doesn't matter literally doesn't matter you know i i guess i code most of the time in vim like literally i'm using an editor from the 70s you know you didn't didn't make anything better okay vs code is nice for reading code there's a few things that are nice about it uh i think that there you can build much better tools how like idas x refs work way better than vx vs codes why yeah actually that's a good question like why i i still use sorry emacs for most uh i've actually never i have to confess something dark so i've never used them okay this i think maybe i'm just afraid that my life has been a like a waste i'm so i'm not i'm not even jellicle about emacs i think this this is how i feel about tensorflow vs pie torch yeah having just like we've switched everything to pie torch now put months into the switch i have felt like i've wasted years on tensorflow i can't believe it i can't believe how much better pie torches yeah i've used emacs in vim doesn't matter yeah still just my my heart somehow i fell in love with lisp i don't know why you can't the heart wants with the heart wants i don't i don't understand it but it just connected with me maybe it's the functional language at first i connected with maybe it's because so many of the ai courses before the deep learning revolution were taught with lisp in mind i don't know i don't know what it is but i'm i'm stuck with it but at the same time like why am i not using a modern id for some of these programming i don't know they're not that much better i've used modern id used to but at the same time so like to just we're not to disagree with you but like i like multiple monitors like i have to do work on a laptop and it's a it's a pain in the ass and also i'm addicted to the kinesis weird keyboard that you could you could see there uh yeah so you don't have any of that you can just be in a on a macbook i mean look at work i have three 24 inch monitors i have a happy hacking keyboard i have a razor death header mouse like but it's not essential for you now let's go to uh day in the life of george hotz what is the perfect day productivity wise so we're not talking about like hunter s thompson uh drugs and uh let's let's look at productivity like what what's the day look like i'm like hour by hour is there any regularities that create a magical george hotz experience i can remember three days in my life and i remember these days vividly when i've gone through kind of radical transformations to the way i think and what i would give i would pay a hundred thousand dollars if i could have one of these days tomorrow um the days have been so impactful and one was first discovering leis of utkowski on the singularity and reading that stuff and like you know my mind was blown um and the next was discovering uh the hunter price and that ai is just compression like finally understanding ai xi and what all of that was you know i like read about it when i was 1819 i didn't understand it and then the fact that like lossless compression implies intelligence the day that i was shown that um and then the third one is controversial the day i found a blog called unqualified reservations and uh read that and i was like wait which one is that that's uh what's the guy's name courtesy arvin yeah so many people tell me i'm supposed to talk to him yeah the day he sounds insane or brilliant but insane or both i don't know the day i found that blog was another like this was during like like gamer gate and kind of the run up to the 2016 election and i'm like wow okay the world makes sense now this this like i had a framework now to interpret this just like i got the framework for ai and a framework to interpret technological progress like those days when i discovered these new frameworks or oh interesting it's just not about but what was special about those days how those days come to be is it just you got lucky like sure i like what you just encountered a hotter prize on uh on hack and use or something like that um like what but you see i don't think it's just see i don't think it's just that like i could have gotten lucky at any point i think that in a way you were ready at that moment yeah exactly to receive the information but is there some magic to the day today of like like eating breakfast and it's the mundane things nothing no i drift i drift through life without structure i drift through life hoping and praying that i will get another day like those days and there's nothing in particular you do to uh to be a receptacle for another for day number four no i didn't do anything to get the other ones so i don't think i have to really do anything now i took a month long trip to new york and the ethereum thing was the highlight of it but the rest of it was pretty terrible i did a two week road trip and i got i had to turn around i had to turn around i'm driving in uh in gunnison colorado i passed through gunnison and uh the snow starts coming down there's a pass up there called monarch pass in order to get through to denver you got to get over the rockies and i had to turn my car around i couldn't i watched uh i watched a f150 go off the road i'm like i gotta go back and like that day was meaningful because like like it was real like i actually had to turn my car around um it's rare that anything even real happens in my life even as you know mundane is the fact that yeah there was snow i had to turn around stay in gunnison leave the next day something about that moment felt real okay so actually it's interesting to break apart the three moments you mentioned if it's okay so it'll uh i always have trouble pronouncing his name but allows a yorkowski yeah so what how did your worldview change in starting to consider the the exponential growth of ai and agi that he thinks about and the the threats of artificial intelligence and all that kind of ideas like can you is it just like can you maybe uh break apart like what exactly was so magical to you was a transformational experience today everyone knows him for threats and ai safety um this was pre that stuff there was i don't think a mention of ai safety on the page um this is this is old yorkowski stuff he'd probably denounce it all now he'd probably be like that's exactly what i didn't want to happen sorry man uh is there something specific you can take from his work that you can remember yeah uh it was this realization that uh computers double in power every 18 months and humans do not and they haven't crossed yet but if you have one thing that's doubling every 18 months and one thing that's staying like this you know here's your log graph here's your line you know you calculate that okay and that did that open the door to the exponential thinking like thinking that like you know what with technology we can actually transform the world it opened the door to human obsolescence it it opened the door to realize that in my lifetime humans are going to be replaced and then the matching idea to that of artificial intelligence with a hunter prize you know i'm torn i go back and forth on what i think about it yeah but the the the basic thesis is it's nice it's a nice compelling notion that we can reduce the task of creating an intelligent system a generally intelligent system into the task of compression so you you can think of all of intelligence in the universe in fact is a kind of compression do you find that a was that just at the time you found that as a compelling idea do you still find that a compelling idea i still find that a compelling idea um i think that it's not that useful day to day but actually um one of maybe my quests before that was a search for the definition of the word intelligence and i never had one and i definitely have a definition of the word compression it's a very uh simple uh straightforward one and uh you know what compression is you know what lossless is lossless compression not lossy lossless compression and that that is equivalent to intelligence which i believe i'm not sure how useful that definition is day to day but like i now have a framework to understand what it is and he just 10x the the uh the prize for that competition like recently a few months ago you ever thought of taking a crack at that oh i did oh i did i spent i spent the next after i found the prize i spent the next six months of my life trying it and uh well that's when i started learning everything about ai and then i worked with vicarious for a bit and then i learned read all the deep learning stuff and i'm like okay now i like i'm caught up to modern ai wow and i had i had a really good framework to put it all in from the compression stuff right like some of the first uh some of the first deep learning models i played with were uh or ggpt gpt basically but before transformers before it was still uh rnn's to to do uh character prediction but by the way on the compression side i mean the the especially neural networks what do you make of the lossless requirement with the harder prize so you know human intelligence and neural networks can probably compress stuff pretty well but there would be lossy it's imperfect uh you can turn a lossy compression into a lossless compressor pretty easily using an arithmetic encoder right you can take an arithmetic encoder and you can just encode the noise with maximum efficiency right so even if you can't predict exactly what the next character is the better a probability distribution you can put over the next character you can then use an arithmetic encoder to uh right you don't have to know whether it's an ear and eye you just have to put good probabilities on them and then you know code those and if you have it's a bit of entropy thing right so let me on that topic it'd be interesting as a little side tour what are your thoughts in this year about gpt3 and these language models and these transformers is there something interesting to you as an ai researcher or is there something interesting to you as an autonomous vehicle developer nah i think uh i think it's arrived i mean it's not like it's cool it's cool for what it is but no we're not just going to be able to scale up to gpg12 and get general purpose intelligence like your loss function is literally just you know you know cross entropy loss on the character right like that's not the loss function of general intelligence is that obvious to you yes can you imagine that like to play devil's advocate on yourself is it possible that you can the gpt12 will achieve general intelligence with something as dumb as this kind of loss function i guess it depends what you mean by general intelligence so there's another problem with the gpt's and that's that they don't have a uh they don't have long term memory right all right so like just gpt12 a scaled up version of gpt2 or 3 i find it hard to believe well you can scale it and it's yeah so it's a hard quarter hard coded length but you can make it wider and wider and wider yeah you're gonna get you're gonna get cool things from those systems but i don't think you're ever gonna get something that can like you know build me a rocket ship what about solve driving so you know you can use transformer with video for example you think is there something in there no because i mean look we use we use a grew we use a grew we could change that grew out to a transformer um i think driving is much more marcovian than language so marcovian you mean like the memory which which aspect of marcovian i mean that like most of the information in the state at t minus one is also in the info is in state t right and it kind of like drops off nicely like this whereas sometime with language you have to refer back to the third paragraph on the second page i feel like there's not many like like you can say like speed limit signs but there's really not many things in autonomous driving that look like that but if you look at uh to play devil's advocate is uh the risk estimation thing that you've talked about is kind of interesting is uh it feels like there might be some longer term uh aggregation of context necessary to be able to figure out like the context i'm not even sure i'm i'm believing my my own devil's we have a nice we have a nice like vision model which outputs like a a one or two four dimensional perception space um can i try transformers on it sure i probably will at some point we'll try transformers and then we'll just see do they do better sure i'm but it might not be a game changer you know well i'm not like like might transformers work better than grooves for autonomous driving sure might we switch sure is this some radical change no okay we use a slightly different you know we switch from r and ns to grooves like okay maybe it's grease to transformers but no it's not yeah well on the on the topic of general intelligence i don't know how much i've talked to you about it like what um do you think we'll actually build an agi like if you look at ray korswell with singularity do you do you have like an intuition about you're kind of saying driving is easy yeah and i i tend to personally believe that solving driving will have really deep important impacts on our ability to solve general intelligence like i i think driving doesn't require general intelligence but i think they're going to be neighbors in a way that it's like deeply tied because it's so like driving is so deeply connected to the human experience that i think solving one will help solve the other but but so i don't see i don't see driving is like easy and almost like separate than general intelligence but like what's your vision of the future with a singularity do you see there will be a single moment like a singularity where it'll be a phase shift are we in the singularity now like what do you have crazy ideas about the future in terms of agi we're definitely in the singularity now um we are of course of course look at the bandwidth between people the bandwidth between people goes up all right um the singularity is just you know in the bandwidth but what do you mean by the bandwidth of people communications tools the whole world is networked the whole world is networked and we raise the speed of that network right oh so you think the communication of information in a distributed way is a empowering thing for collective intelligence oh i didn't say it's necessarily a good thing but i think that's like when i think of the definition of the singularity yeah it seems kind of right i see like it's a change in the world beyond which like the world would be transformed in ways that we can't possibly imagine no i mean i think we're in the singularity now in the sense that there's like you know one world in a monoculture and it's also linked yeah i mean i kind of share the intuition that the the singularity will originate from the collective intelligence of us ants versus the like some single system agi type thing oh i totally agree with that yeah i don't i don't really believe in like like a hard takeoff agi kind of thing um yeah i don't think i don't even think ai is all that difference in kind from what we've already been building um with respect to driving i think driving is a subset of general intelligence and i think it's a pretty complete subset i think the tools we develop at comma will also be extremely helpful to solving general intelligence and that's i think the real reason why i'm doing it i don't care about self driving cars it's a cool problem to beat people at but yeah i mean yeah you're kind of you're of two minds so one you do have to have a mission and you want to focus and make sure you get you get there you can't forget that but at the same time there is a thread that's much bigger than uh the kinesis the entirety of your effort that's much bigger than just driving with ai and with general intelligence it is so easy to delude yourself into thinking you've figured something out when you haven't if we build a level five self driving car we have indisputably built something yeah is it general intelligence i'm not going to debate that i will say we've built something that provides huge financial value yeah beautifully put that's the engineer and credo like just just build the thing it's like that's why i'm with uh with uh with with ilan on uh go to mars yeah that's a great one you can argue like who the hell cares about going to mars but the reality is set that as a mission get it done yeah and then you're going to crack some pro problem that you've never even expected in the process of doing that yeah yeah i mean no i think if i had a choice between you managed to go on a mars and solving self driving cars i think going to mars is uh better but i don't know i'm more suited for self driving cars i'm an information guy i'm not a modernist i'm a postmodernist postmodernist all right beautifully put let me let me drag you back to programming for a second what three maybe three to five programming languages should people learn do you think like if you look at yourself what did you get the most out of from learning uh well so everybody should learn see an assembly we'll start with those two right assembly yeah if you can't code an assembly you don't know what the computer's doing you don't understand like you don't have to be great in assembly but you have to code in it and then like you have to appreciate assembly in order to appreciate all the great things see gets you and then you have to code and see in order to appreciate all the great things python gets you so i'll just say assembly see in python we'll start with those three the memory allocation of c and the the the fact that so assembly is to give you a sense of just how many levels of abstraction you get to work on in modern day programming yeah yeah graph coloring for assignment register assignment and compilers yeah like you know you got to do you know the compiler your computer only has a certain number of registers yet you can have all the variables you want to see function you know so you get to start to build intuition about compilation like what a compiler gets you what else um well then there is then there's kind of uh so those are all very imperative programming languages um then there's two other paradigms for programming that everybody should be familiar with i'm one of them is functional uh you should learn haskell and take that all the way through learn a language with dependent types like cock um learn that whole space like the very pl theory heavy languages and haskell is your favorite functional what is that the go to you'd say yeah i'm not a great haskell programmer i wrote a compiler and haskell ones there's another paradigm and actually there's one more paradigm that i'll even talk about after that that i never used to talk about when i would think about this but the next paradigm is learn verilog or hdl um understand this idea of all of the instructions executed once if i have a block in verilog and i write stuff in it it's not sequential they all execute it once and then like think like that that's how hard it works to be so i guess assembly doesn't quite get you that assembly is more about compilation and verilog is more about the hardware like giving a sense of what actually is the hardware is doing assembly see python are straight like they sit right on top of each other in fact c is well let me see it's kind of coded in c but you could imagine the first c was coded in assembly and python is actually coded in c um so you know you can straight up go on that got it and then verilog gives you that's brilliant okay and then i think there's another one now everyone's karpathy calls it programming 2.0

which is learn a i'm not even gonna don't learn tensorflow learn pytorch so machine learning we've got to come up with a better term than programming 2.0 or um but yeah it's a programming language learn it i wonder if it can be formalized a little bit better which we feel like we're in the early days of what that actually entails data driven programming data driven programming yeah but it's so fundamentally different as a paradigm than the others like it almost requires a different skill set but you think it's still yeah and pytorch versus tensorflow pytorch wins it's the fourth paradigm it's the fourth paradigm that i've kind of seen there's like this you know imperative functional hardware i don't know a better word for it and then ml do you have advice for people uh that want to you know get into programming want to learn programming you have a video uh what is programming noob lessons exclamation point and i think the top comment is like warning this is not for noobs uh do you have a noob like uh tldw for that video but also a noob friendly advice on how to get into programming you are never going to learn programming by watching a video called learn programming the only way to learn programming i think and the only one is it the only way everyone i've ever met who can program well learned it all in the same way they had something they wanted to do and then they tried to do it and then they were like oh well okay this is kind of you know be nice as a computer could kind of do this and then you know that's how you learn you just keep pushing on a project so the only advice i have for learning programming is go program somebody wrote to me a question like we don't really they're looking to learn about recurring on networks and saying like my company is thinking of doing recur using recurrent neural networks for time series data but we don't really have an idea of where to use it yet we just want to like do you have any advice on how to learn about these are these kind of general machine learning questions and i think the answer is like actually have a problem that you're trying to solve and and just i see that stuff oh my god when people talk like that they're like i heard machine learning is important could you help us integrate machine learning with macaroni and cheese production you just i don't even you can't help these people like who lets you run anything who lets that kind of person run anything i think we're all we're all beginners at some point so it's not like they're a beginner it's it's like my problem is not that they don't know about machine learning my problem is that they think that machine learning has something to say about macaroni and cheese production or like i heard about this new technology how can i use it for why like i don't know what it is but how can i use it for why that's true you have to build up an intuition of how because you might be able to figure out a way but like the prerequisites you should have a macaroni and cheese problem to solve first exactly and then two you should have more traditional like in the learning process involve more traditionally applicable problems in the space of whatever that is of machine learning and then see if it can be applied to me at least start with tell me about a problem like if you have a problem you're like you know some of my boxes aren't getting enough macaroni in them um can we use machine learning to solve this problem that's much much better than how do i apply machine learning to macaroni and cheese one big thing maybe this is me uh talking to the audience a little bit because i get these days so many messages a device on how to like learn stuff okay my this this this is not me being mean i think this is quite profound actually is you should google it oh yeah like one of the uh like skills that you should really acquire as an engineer as a researcher as a thinker like one there's two two two complementary skills like one is with a blank sheet of paper with no internet to think deeply and then the other is to google the crap out of the questions you have like that's actually a skill i don't people often talk about but like doing research like pulling at the thread like looking up different words going into like github repositories with two stars and like looking how they did stuff like looking at the code or going on twitter seeing like there's little pockets of brilliant people that are like having discussions like if you're a neuroscientist go into signal processing community if you're an ai person going into the psychology community like the switch communities i keep searching searching searching because it's so much better to invest in like finding somebody else who already solved your problem then then is to try to solve the problem and because they've often invested years of their life like entire communities are probably already out there who have tried to solve your problem i think they're the same thing i think you go try to solve the problem and then in trying to solve the problem if you're good at solving problems you'll stumble upon the person who solved it already yeah but the stumbling is really important i think that's the skill that people should really put especially in undergrad like search if you ask me a question how should i get started in deep learning especially like especially like that is just so googleable like the whole point is you google that and you get and you get a million pages and just start looking at them yeah start pulling at the threads start exploring start taking notes start getting advice from a million people that already like spent their life answering that question actually oh well yeah i mean that's definitely also yeah when people like ask me things like that i'm like trust me the top answer on google is much much better than anything i'm going to tell you right yeah people ask it's an interesting question let me know if you have any recommendations what three books technical or fiction or philosophical had an impact on your life or you wouldn't recommend perhaps uh maybe we'll start with the least controversial uh infinite jest um infinite jest is a do you have a foster house yeah it's a book about wireheading really uh very enjoyable to read very well written you know you will you will you will grow as a person reading this book uh it's effort um and i'll set that up for the second book which is pornography that's called atlas shrugged um which um atlas shrugged is pornography i mean it is i will not i will not defend the i will not say atlas shrugged is a well written book um it is entertaining to read certainly just like pornography the production value isn't great um you know there's a 60 page uh monologue in there that anran's editor really wanted to take out and she uh paid she paid out of her pocket to keep that 60 page monologue in the book um but it is a great book for a kind of framework um of human relations and i know a lot of people are like yeah but it's a terrible framework yeah but it's a framework just for context in a couple days i'm speaking with for probably four plus hours with yaron brook who's the main living remaining objectivists objectivist interest uh so i've always found this philosophy quite interesting on many levels one of how repulsive some percent of the large percent of the population find it which is always uh always funny to me when people are like unable to even read a philosophy because um of some i think that says more about their psychological perspective on it yeah but but there is something about objectivism and anran's philosophy that's really deeply connected to this idea of capitalism of uh the ethical life is the productive life um that was always um compelling to me it didn't seem as like i didn't seem to interpret it in the negative sense that some people do to be fair i read the book when i was 19 so you had an impact at that point yeah yeah and the bad guys in the book have this slogan from each according to their ability to each according to their need and i'm looking at this and i'm like these are the most cart this is team rocket level cartoonishness right no bad and then when i realized that was actually the slogan of the communist party i'm like wait a second wait no no no no no just you're telling me this really happened yeah it's interesting i mean one of the criticisms of her work is she has a cartoonish view of good and evil like that there's like the the reality isn't jordan peterson says is that each of us have the capacity for good and evil in us as opposed to like there's some characters who are purely evil and some characters are purely good and that's in a way why it's pornographic the production value i love it well evil is punished and there's very clearly like you know no there's no there's no you know uh just like porn doesn't have uh you know like character growth well you know neither does alish around like brilliant well put but at 19 year old george hotz it was uh it was good enough yeah yeah yeah what uh what's the third you have something um i could give i these these two i'll just throw out uh their sci fi uh perbutation city um great things just try thinking about copies yourself and then um them by science that is uh greg eagan uh he's uh that might not be his real name some australian guy might not be australian i don't know um and then this one's online it's called the metamorphosis of prime intellect um it's a story set in a post singularity world it's interesting is there uh can you either of the worlds do you find something uh philosophy interesting in them that you can come in on i mean it is clear to me that uh metamorphosis of prime intellect is like written by an engineer uh which is it's very it's very almost a pragmatic take on a utopia in a way positive or negative is that well that's up to you to decide reading the book and the ending of it is very interesting as well and i didn't realize what it was i first read that when i was 15 i've reread that book several times in my life and it's short it's 50 pages i want to go read it what's uh sorry it's a little tangent i've been working through the foundation i've been i've haven't read much sci fi my whole life and i'm trying to fix that uh the last few months that's been a little side project what's uh to use the greatest sci fi novel uh that uh people should read or is it or i mean i would i would yeah i would i would say like yeah parametrician city metamorphosis of prime intellect um i don't know i i didn't like foundation i thought it was way too modernist you like dune and like all of those i've never read dune i've never read dune i i have to read it uh fire upon the deep is interesting uh okay i mean look everyone should read everyone should read neuromancer everyone should read snow crash if you haven't read those like start there um yeah i haven't read snow crash never snow crash oh it's i mean it's very interesting go to lesher bach and if you want the controversial one bronze age mindset all right i'll look into that one those aren't sci fi but just to round out books so a bunch of people asked me on twitter and read it and so on for advice so what advice would you give a young person today about life what uh yeah i mean looking back you especially when you're a young younger you did uh and you continued it you've accomplished a lot of interesting things is there some advice from those from that life of yours that you can pass on if college ever opens again i would love to give a graduation speech um at that point i will put a lot of somewhat satirical effort into this question yeah at this uh you haven't written anything at this point oh you know what always wear sunscreen this is water like your plagiarism i mean you know but but that's the that's the like clean your room you know yeah you can plagiarism from from all of this stuff and it's it's there is no self help books aren't designed to help you they're designed to make you feel good like whatever advice i could give you already know everyone already knows sorry it doesn't feel good right like you know you know i don't know what if i tell you that you should you know know eat well and and and read more and it's not going to do anything i think the whole like genre of those kind of questions is is is meaningless i don't know if anything it's don't worry so much about that stuff don't be so caught up in your head right i mean you're yeah in the sense that your whole life if your whole existence is like moving version of that advice i don't know yeah and there's there's something i mean there's something in you that resists that kind of thinking in that in itself is it's just illustrative of who you are and there's something to learn from that i think you're you're clearly not overthinking stuff yeah and you know there's a gut thing i even when i talk about my advice i'm like my advice is only relevant to me yeah it's not relevant to anybody else i'm not saying you should go out if you're the kind of person who overthinks things to stop overthinking things it's not bad it doesn't work for me maybe it works for you i you know i don't know let me ask you about love yeah uh so you i think last time we talked about the meaning of life and it was it was kind of about winning of course uh i don't think i've talked to you about love much whether romantic or just love for the common humanity amongst us all what role has love played in your life in this in this quest for winning where does love fit in well where love i think means several different things there's love in the sense of maybe i could just say there's like love in the sense of opiates and love in the sense of oxytocin and then love in the sense of maybe like a love for math i don't think fits into either those first two paradigms uh so each of those have they uh have they have they given something to you in your life i'm not that big of a fan of the first two um why why the same reason i'm not a fan of you know for the same reason i don't do opiates and don't take ecstasy right and there were times look i've tried both um i like opiates way more than electric ecstasy uh but they're not the ethical life is the productive life so maybe that's my problem with with with those and then like yeah a sense of i don't know like abstract love for humanity i mean the abstract love for humanity i'm like yeah i've always felt that and i guess it's hard for me to imagine not feeling it and maybe people who don't and i don't know but yeah that's just like a background thing that's there i mean since we brought up uh drugs let me ask you you this is becoming more and more part of my life because i'm talking to a few researchers that work on psychedelics i've eaten shrooms a couple times and it was fascinating to me that like the mind can go like just fascinating the mind can go to places i didn't imagine it could go and i was very friendly and positive and exciting and everything was kind of hilarious in in the in the place wherever my mind went that's where what is uh what do you think about psychedelics do you think they have what do you think the mind goes have you done psychedelics what do you where do you think the mind goes uh is there something useful to learn about the places it goes once you come back you know i find it interesting that this idea that psychedelics have something to teach is almost unique to psychedelics right people don't argue this about amphetamines and that's true and i'm not really sure why yeah i think all of the drugs have lessons to teach i think there's things to learn from opiates i think there's things to learn from amphetamines i think there's things to learn from psychedelics things to learn from marijuana um but also at the same time recognize that i don't think you're learning things about the world i think you're learning things about yourself yes um and you know what's the even i might have even been uh might have even been a timothy leary quote i don't know what's called but the idea is basically like you know everybody should look behind the door but then once you've seen behind the door you don't need to keep going back um so i mean and that's my thoughts on on all real drug use too so maybe for caffeine it's a it's a little experience that uh it's good to have but oh yeah no i mean yeah i guess yeah psychedelics are definitely so you're a fan of new experiences i suppose yes because they all contain a little especially the first few times it contains some lessons that can be picked up yeah and i'll i'll i'll revisit psychedelics maybe once a year um usually small smaller doses maybe they turn up the learning rate of your brain i've heard that like that yeah that's cool big learning rates have frozen comms last question this is a little weird one but you've called yourself crazy in the past uh first of all on a scale of one to ten how crazy would you say are you oh i mean it depends how you you know when you compare me to ilan moskin i'd say levandowski not so crazy so like like a seven let's go with six six six six what uh well i like seven seven's a good number seven all right well yeah i'm sure day by day changes right so but you're in that in that area what uh in thinking about that what do you think is the role of madness is that a feature or a bug if you were to dissect your brain so okay from like a like mental health lens on crazy i'm not sure i really believe in that i'm not sure i really believe in like a lot of that stuff right this concept of okay you know when you get over to like like like like like hardcore bipolar and schizophrenia these things are clearly real somewhat biological and then over here on the spectrum you have like add and oppositional defiance disorder and these things that are like wait this is normal spectrum human behavior like this isn't you know where's the the line here and why is this like a problem so there's this whole you know the neurodiversity of humanity is it's huge like people think i'm always on drugs people are saying this to me on my streams and like guys you know like i'm real open with my drug use i'd tell you if i was on drugs and i mean i had like a cup of coffee this morning but other than that this is just me you're witnessing my brain in action you so so the word madness doesn't even make sense and then you're in the rich neurodiversity of humans i think it makes sense but only for our like some insane extremes like if you are actually like visibly hallucinating you know that's okay but there is the kind of spectrum on which you stand out like that that's uh like if i were to look you know at decorations on a christmas tree or something like that like if you were a decoration out that would catch my eye like that thing is sparkly whatever the hell that thing is uh there's something to that just like refusing to be um boring or maybe boring is the wrong word but to um yeah i mean be willing to sparkle you know it's it's like somewhat constructed i mean i am who i choose to be uh i'm gonna say things as true as i can see them i'm not gonna i'm not gonna lie and but that's a really important feature in itself so like whatever the neurodiversity of your whatever your brain is not putting constraints on it that force it to to fit into the mold of what society is like defines what you're supposed to be so you're one of the specimens that that doesn't mind being yourself being right is super important except at the expense of being wrong without breaking that apart i think it's a beautiful way to end it george you're one of the most special humans i know it's truly an honor to talk to you thanks so much for doing it thank you for having me thanks for listening to this conversation with george hotz and thank you to our sponsors for sigmatic which is the maker of delicious mushroom coffee decoding digital which is a tech podcast that i listen to and enjoy and express vpn which is the vpn i've used for many years please check out these sponsors in the description to get a discount and to support this podcast if you enjoy this thing subscribe on youtube review it with five stars and apple podcast follow on spotify support on patreon or connect with me on twitter at lex freedman and now let me leave you with some words from the great and powerful linus torvald talk is cheap show me the code thank you for listening and hope to see you next time


